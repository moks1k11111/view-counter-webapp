from fastapi import FastAPI, HTTPException, Depends, Header, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, List, Dict
from datetime import datetime, timedelta
import sys
import os
import hmac
import hashlib
import json
import asyncio
import logging
from urllib.parse import parse_qsl
from collections import defaultdict

# Telegram Bot Imports
from telegram import Update, WebAppInfo, KeyboardButton, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, ContextTypes

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from database_sheets import SheetsDatabase
from database_sqlite import SQLiteDatabase
from project_manager import ProjectManager
from project_sheets_manager import ProjectSheetsManager
from cache import (
    cache, TTL_PROJECT_ANALYTICS, TTL_USER_ANALYTICS, TTL_FINISHED_PROJECT,
    get_project_analytics_key, get_user_analytics_key
)
from config import (
    TELEGRAM_TOKEN, DEFAULT_GOOGLE_SHEETS_NAME, GOOGLE_SHEETS_CREDENTIALS,
    GOOGLE_SHEETS_CREDENTIALS_JSON, ADMIN_IDS,
    RAPIDAPI_KEY, RAPIDAPI_HOST, RAPIDAPI_BASE_URL,
    INSTAGRAM_RAPIDAPI_KEY, INSTAGRAM_RAPIDAPI_HOST, INSTAGRAM_BASE_URL,
    FACEBOOK_RAPIDAPI_KEY, FACEBOOK_RAPIDAPI_HOST, FACEBOOK_APP_ID,
    DB_ENCRYPTION_KEY, LOG_CHANNEL_ID
)
from tiktok_api import TikTokAPI
from instagram_api import InstagramAPI
from facebook_parser import FacebookAPI

# Email Farm imports
from email_farm_models import EmailFarmDatabase
from email_encryption import EmailEncryption, get_encryption
from email_imap_client import OutlookIMAPClient
from email_oauth2_client import OutlookOAuth2IMAPClient
from email_smart_filter import EmailSmartFilter
from email_sheets_manager import EmailSheetsManager

# Logging (initialize BEFORE using logger)
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# WebApp Config
WEBAPP_URL = "https://moks1k11111.github.io/view-counter-webapp/index.html"

# Celery tasks (background processing)
try:
    from tasks import sync_account_to_sheets, sync_project_to_sheets
    CELERY_AVAILABLE = True
    logger.info("‚úÖ Celery tasks imported successfully")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Celery not available: {e}. Background tasks disabled.")
    CELERY_AVAILABLE = False

app = FastAPI(title="View Counter WebApp API")

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Telegram WebApp
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–æ–º–µ–Ω
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
db = SQLiteDatabase()

# –ò—Å–ø–æ–ª—å–∑—É–µ–º GOOGLE_SHEETS_CREDENTIALS_JSON –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ (Railway), –∏–Ω–∞—á–µ —Ñ–∞–π–ª (–ª–æ–∫–∞–ª—å–Ω–æ)
try:
    sheets_db = SheetsDatabase(GOOGLE_SHEETS_CREDENTIALS, DEFAULT_GOOGLE_SHEETS_NAME, GOOGLE_SHEETS_CREDENTIALS_JSON)
except Exception as e:
    print(f"‚ö†Ô∏è  Google Sheets –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω: {e}")
    print("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å SQLite –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö")
    sheets_db = None

project_manager = ProjectManager(db)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
# –§–æ—Ä–º–∞—Ç: {project_id: {platform: {total, processed, updated, failed}}}
refresh_progress = defaultdict(lambda: defaultdict(lambda: {'total': 0, 'processed': 0, 'updated': 0, 'failed': 0}))

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Google Sheets –¥–ª—è –ø—Ä–æ–µ–∫—Ç–æ–≤
try:
    project_sheets = ProjectSheetsManager(GOOGLE_SHEETS_CREDENTIALS, "MainBD", GOOGLE_SHEETS_CREDENTIALS_JSON)
except Exception as e:
    print(f"‚ö†Ô∏è  Project Sheets Manager –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω: {e}")
    project_sheets = None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
try:
    tiktok_api = TikTokAPI(api_key=RAPIDAPI_KEY, api_host=RAPIDAPI_HOST, base_url=RAPIDAPI_BASE_URL)
    instagram_api = InstagramAPI(api_key=INSTAGRAM_RAPIDAPI_KEY, api_host=INSTAGRAM_RAPIDAPI_HOST, base_url=INSTAGRAM_BASE_URL)
    facebook_api = FacebookAPI(api_key=FACEBOOK_RAPIDAPI_KEY, api_host=FACEBOOK_RAPIDAPI_HOST, app_id=FACEBOOK_APP_ID)
    logger.info("‚úÖ TikTok, Instagram and Facebook API clients initialized")
except Exception as e:
    logger.error(f"‚ö†Ô∏è  Failed to initialize API clients: {e}")
    tiktok_api = None
    instagram_api = None
    facebook_api = None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Email Farm
try:
    email_farm_db = EmailFarmDatabase(db_path="tiktok_analytics.db")
    email_encryption = get_encryption()
    email_filter = EmailSmartFilter()
    logger.info("‚úÖ Email Farm system initialized")
except Exception as e:
    logger.error(f"‚ö†Ô∏è  Failed to initialize Email Farm: {e}")
    email_farm_db = None
    email_encryption = None
    email_filter = None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Email Sheets Manager –¥–ª—è Email Farm
try:
    json_creds_preview = GOOGLE_SHEETS_CREDENTIALS_JSON[:50] + "..." if GOOGLE_SHEETS_CREDENTIALS_JSON else "None"
    logger.info(f"üìä Initializing Email Sheets Manager:")
    logger.info(f"   credentials_file={GOOGLE_SHEETS_CREDENTIALS}")
    logger.info(f"   has_json_creds={bool(GOOGLE_SHEETS_CREDENTIALS_JSON)}")
    logger.info(f"   json_creds_length={len(GOOGLE_SHEETS_CREDENTIALS_JSON) if GOOGLE_SHEETS_CREDENTIALS_JSON else 0}")
    logger.info(f"   json_creds_preview={json_creds_preview}")

    email_sheets = EmailSheetsManager(GOOGLE_SHEETS_CREDENTIALS, "PostBD", GOOGLE_SHEETS_CREDENTIALS_JSON)
    logger.info("‚úÖ Email Sheets Manager (PostBD) initialized successfully")
    logger.info(f"   Spreadsheet: {email_sheets.spreadsheet.title}")
except Exception as e:
    logger.error(f"‚ùå Failed to initialize Email Sheets Manager: {e}")
    import traceback
    logger.error(traceback.format_exc())
    logger.error("‚ö†Ô∏è Email Farm will work WITHOUT Google Sheets persistence - emails will be lost on restart!")
    email_sheets = None

# ============ TELEGRAM BOT LOGIC ============

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handler for /start command"""
    logger.info(f"Received /start from {update.effective_user.id}")

    try:
        user = update.effective_user

        # Register user in database
        try:
            print(f"üîç DEBUG: Saving user to DB - ID: {user.id}, Username: {user.username}, Name: {user.first_name} {user.last_name}")
            db.add_user(user.id, user.username, user.first_name, user.last_name)
            print(f"‚úÖ User {user.id} (@{user.username}) saved/updated in persistent DB")
        except Exception as e:
            print(f"‚ö†Ô∏è Error saving user: {e}")
            import traceback
            traceback.print_exc()

        keyboard = [
            [KeyboardButton(
                text="üìä –û—Ç–∫—Ä—ã—Ç—å –ê–Ω–∞–ª–∏—Ç–∏–∫—É",
                web_app=WebAppInfo(url=WEBAPP_URL)
            )]
        ]
        reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

        await update.message.reply_text(
            f"üëã –ü—Ä–∏–≤–µ—Ç, {user.first_name}!\n\n"
            "–°–µ—Ä–≤–µ—Ä Render —Ä–∞–±–æ—Ç–∞–µ—Ç ‚úÖ\n"
            "–ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ, —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å –ø–∞–Ω–µ–ª—å –∞–Ω–∞–ª–∏—Ç–∏–∫–∏:",
            reply_markup=reply_markup
        )
    except Exception as e:
        logger.error(f"Error in start_command: {e}")

async def run_telegram_bot():
    """Background task to run the Telegram bot"""
    if not TELEGRAM_TOKEN:
        logger.error("‚ùå No TELEGRAM_TOKEN found")
        return

    logger.info("üöÄ Starting Telegram Bot in background...")
    try:
        bot_app = Application.builder().token(TELEGRAM_TOKEN).build()
        bot_app.add_handler(CommandHandler("start", start_command))

        # –í–ê–ñ–ù–û: –£–¥–∞–ª—è–µ–º webhook –ø–µ—Ä–µ–¥ polling
        logger.info("Deleting webhook...")
        await bot_app.bot.delete_webhook(drop_pending_updates=True)

        # Start polling
        logger.info("Starting polling...")
        await bot_app.initialize()
        await bot_app.start()
        await bot_app.updater.start_polling()

        logger.info("‚úÖ Bot polling started successfully on Render")

        # Keep running
        while True:
            await asyncio.sleep(1)

    except Exception as e:
        logger.error(f"‚ùå Bot failed to start: {e}")

async def sync_emails_from_sheets():
    """
    Load all emails from Google Sheets and sync them to SQLite on startup.
    This ensures emails persist across Render restarts.
    """
    if not email_sheets or not email_farm_db or not email_encryption:
        logger.warning("‚ö†Ô∏è Email Sheets or Email Farm DB not initialized - skipping sync")
        return

    try:
        logger.info("üì• Syncing emails from Google Sheets to SQLite...")

        # Get all emails from PostBD sheet
        all_emails = email_sheets.get_all_emails_for_sheet("Post")
        logger.info(f"   Found {len(all_emails)} emails in Google Sheets")

        synced_count = 0
        skipped_count = 0

        for sheet_email in all_emails:
            email_address = sheet_email['email']

            # Check if email already exists in SQLite
            existing = email_farm_db.get_email_by_address(email_address)

            if existing:
                # Email already exists, just update status if needed
                skipped_count += 1
                continue

            # Email doesn't exist, add it
            try:
                # Use empty password as placeholder since passwords are not stored in sheets
                # The real encrypted password is in SQLite, but we lost it on restart
                # Admin will need to re-upload with passwords if needed
                placeholder_password = email_encryption.encrypt("")

                email_id = email_farm_db.add_email_account(
                    email=email_address,
                    password_encrypted=placeholder_password,
                    proxy_string=None,  # Proxy info not stored in sheets
                    project_id=None
                )

                if email_id:
                    synced_count += 1

                    # Restore status and assignment from sheets if email was allocated
                    if sheet_email['status'] == 'active' and sheet_email['user_id']:
                        try:
                            user_id = int(sheet_email['user_id'])
                            email_farm_db.allocate_email_to_user(email_id, user_id)

                            # Restore is_completed status
                            if sheet_email.get('is_completed') == '1':
                                email_farm_db.mark_email_completed(email_id)

                            logger.info(f"   ‚úÖ Synced: {email_address} (user: {user_id}, completed: {sheet_email.get('is_completed') == '1'})")
                        except Exception as e:
                            logger.warning(f"   ‚ö†Ô∏è Could not restore status for {email_address}: {e}")
                    else:
                        logger.info(f"   ‚úÖ Synced: {email_address} (free)")

            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è Could not sync {email_address}: {e}")
                skipped_count += 1

        logger.info(f"‚úÖ Email sync complete: {synced_count} synced, {skipped_count} skipped")

    except Exception as e:
        logger.error(f"‚ùå Error syncing emails from sheets: {e}")
        import traceback
        logger.error(traceback.format_exc())


@app.on_event("startup")
async def startup_event():
    """Start bot when FastAPI starts"""
    print("üöÄ SERVER VERSION: 4.2 (ADDED GOOGLE SHEETS SYNC ON STARTUP)")
    logger.info("üöÄ SERVER VERSION: 4.2 (ADDED GOOGLE SHEETS SYNC ON STARTUP)")
    logger.info("üöÄ FastAPI starting up...")

    # Sync emails from Google Sheets to SQLite
    await sync_emails_from_sheets()

    # Start bot in background (won't crash API if bot fails)
    try:
        asyncio.create_task(run_telegram_bot())
        logger.info("‚úÖ Bot task created successfully")
    except Exception as e:
        logger.error(f"‚ö†Ô∏è Failed to create bot task: {e}")
        logger.info("‚úÖ API will continue without bot")

# ============ –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ============

class UserAuth(BaseModel):
    telegram_init_data: str

class BonusCreate(BaseModel):
    project_id: str
    amount: float
    description: str

class ProjectStats(BaseModel):
    project_id: str
    platform: Optional[str] = None  # tiktok, instagram, –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö

class ProjectCreate(BaseModel):
    name: str
    target_views: int
    kpi_views: int = 1000
    deadline: str  # YYYY-MM-DD
    geo: str = ""
    allowed_platforms: Dict[str, bool] = {}

class SocialAccountCreate(BaseModel):
    platform: str  # tiktok, instagram, youtube, facebook
    username: str
    profile_link: str
    status: str = "NEW"  # NEW, OLD, Ban
    topic: str = ""
    telegram_user: Optional[str] = None  # Worker's Telegram username from frontend

class SocialAccountUpdate(BaseModel):
    status: Optional[str] = None
    topic: Optional[str] = None
    username: Optional[str] = None
    profile_link: Optional[str] = None

class AccountSnapshot(BaseModel):
    followers: int = 0
    likes: int = 0
    comments: int = 0
    videos: int = 0
    views: int = 0

class AddUserToProject(BaseModel):
    username: str

class RefreshStatsRequest(BaseModel):
    platforms: Dict[str, bool]  # {"tiktok": True, "instagram": True, ...}
    date_from: Optional[str] = None  # –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞ (YYYY-MM-DD)
    date_to: Optional[str] = None  # –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∞ (YYYY-MM-DD)

# ============ Email Farm Models ============

class EmailAccountUpload(BaseModel):
    email: str
    password: str
    proxy: Optional[str] = None  # socks5://user:pass@ip:port
    project_id: Optional[int] = None
    refresh_token: Optional[str] = None  # OAuth2 refresh token
    client_id: Optional[str] = None  # OAuth2 client ID
    auth_type: str = 'password'  # 'password' or 'oauth2'

class EmailAccountBulkUpload(BaseModel):
    accounts: List[EmailAccountUpload]

class SetUserEmailLimit(BaseModel):
    user_id: int
    max_emails: int
    can_access: bool = True

class CheckEmailCodeRequest(BaseModel):
    email_id: int

# ============ Email Farm Helper Functions ============

async def send_security_alert(user_id: int, email: str, subject: str, reason: str):
    """Send security alert to admin channel"""
    if not LOG_CHANNEL_ID:
        logger.warning("‚ö†Ô∏è LOG_CHANNEL_ID not configured, skipping security alert")
        return

    try:
        from telegram import Bot
        bot = Bot(token=TELEGRAM_TOKEN)

        message = (
            f"üö® <b>Security Alert - Email Farm</b>\n\n"
            f"üë§ User ID: <code>{user_id}</code>\n"
            f"üìß Email: <code>{email}</code>\n"
            f"üìù Subject: <i>{subject}</i>\n\n"
            f"‚ö†Ô∏è <b>Reason:</b> {reason}\n\n"
            f"üïê Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        )

        await bot.send_message(
            chat_id=LOG_CHANNEL_ID,
            text=message,
            parse_mode='HTML'
        )
        logger.info(f"‚úÖ Security alert sent to channel {LOG_CHANNEL_ID}")

    except Exception as e:
        logger.error(f"‚ùå Failed to send security alert: {e}")

# ============ Telegram WebApp –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è ============

def validate_telegram_init_data(init_data: str) -> dict:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –æ—Ç Telegram WebApp"""
    try:
        parsed_data = dict(parse_qsl(init_data))

        # –ü–æ–ª—É—á–∞–µ–º hash –∏–∑ –¥–∞–Ω–Ω—ã—Ö
        received_hash = parsed_data.pop('hash', None)
        if not received_hash:
            raise HTTPException(status_code=401, detail="Missing hash")

        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        data_check_string = '\n'.join([f"{k}={v}" for k, v in sorted(parsed_data.items())])

        # –°–æ–∑–¥–∞–µ–º —Å–µ–∫—Ä–µ—Ç–Ω—ã–π –∫–ª—é—á
        secret_key = hmac.new(
            b"WebAppData",
            TELEGRAM_TOKEN.encode(),
            hashlib.sha256
        ).digest()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º hash
        calculated_hash = hmac.new(
            secret_key,
            data_check_string.encode(),
            hashlib.sha256
        ).hexdigest()

        if calculated_hash != received_hash:
            raise HTTPException(status_code=401, detail="Invalid hash")

        # –ü–∞—Ä—Å–∏–º user –¥–∞–Ω–Ω—ã–µ
        user_data = json.loads(parsed_data.get('user', '{}'))
        return user_data

    except Exception as e:
        raise HTTPException(status_code=401, detail=f"Auth failed: {str(e)}")

async def get_current_user(x_telegram_init_data: str = Header(None)) -> dict:
    """Dependency –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    print(f"üîç Auth attempt - initData present: {bool(x_telegram_init_data)}, length: {len(x_telegram_init_data) if x_telegram_init_data else 0}")
    if not x_telegram_init_data:
        print("‚ùå Auth failed: No init data")
        raise HTTPException(status_code=401, detail="Telegram init data required")
    try:
        user = validate_telegram_init_data(x_telegram_init_data)
        print(f"‚úÖ Auth success: user_id={user.get('id')}")
        return user
    except HTTPException as e:
        print(f"‚ùå Auth failed: {e.detail}")
        raise

# ============ API Endpoints ============

@app.get("/")
async def root():
    return {"message": "View Counter WebApp API + Telegram Bot", "version": "2.0", "bot_enabled": bool(TELEGRAM_TOKEN)}

@app.get("/api/me")
async def get_me(user: dict = Depends(get_current_user)):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
    user_id = str(user.get('id'))

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–µ–∫—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    projects = project_manager.get_user_projects(user_id)

    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–µ–∫—Ç
    current_project_id = project_manager.get_user_current_project(user_id)

    return {
        "user": user,
        "projects": projects,
        "current_project_id": current_project_id
    }

@app.get("/api/projects")
async def get_projects(user: dict = Depends(get_current_user)):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –ø—Ä–æ–µ–∫—Ç—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–æ—Å—Ç—É–ø–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = str(user.get('id'))
    logger.info(f"üìã User {user_id} requesting all projects")
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã—Ö
    projects = project_manager.get_all_projects_with_access(user_id)
    logger.info(f"üìã Found {len(projects)} projects for user {user_id}")

    # –õ–æ–≥–∏—Ä—É–µ–º access –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    for p in projects:
        logger.info(f"  - Project '{p.get('name')}': has_access={p.get('has_access')}")

    return {"projects": projects}

@app.get("/api/projects/{project_id}")
async def get_project(project_id: str, user: dict = Depends(get_current_user)):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–µ–∫—Ç–µ"""
    user_id = str(user.get('id'))

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø –∫ –ø—Ä–æ–µ–∫—Ç—É
    user_projects = project_manager.get_user_projects(user_id)
    if not any(p['id'] == project_id for p in user_projects):
        raise HTTPException(status_code=403, detail="Access denied")

    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    # –ü–æ–ª—É—á–∞–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞
    users = project_manager.get_project_users(project_id)

    return {
        "project": project,
        "users": users
    }

@app.post("/api/projects/{project_id}/users")
async def add_user_to_project_endpoint(
    project_id: str,
    data: AddUserToProject,
    user: dict = Depends(get_current_user)
):
    """–î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ø—Ä–æ–µ–∫—Ç –ø–æ username"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø –∫ –ø—Ä–æ–µ–∫—Ç—É
    user_id = str(user.get('id'))
    user_projects = project_manager.get_user_projects(user_id)
    if not any(p['id'] == project_id for p in user_projects):
        raise HTTPException(status_code=403, detail="Access denied")

    # Strip @ from username if present
    username = data.username.strip().lstrip('@')

    # Look up user by username in the database (case-insensitive)
    try:
        print(f"üîç DEBUG: Looking up user with username: '{username}' (case-insensitive)")
        db.cursor.execute(
            "SELECT user_id, first_name FROM users WHERE LOWER(username) = LOWER(?)",
            (username,)
        )
        result = db.cursor.fetchone()

        if not result:
            print(f"‚ùå User '{username}' not found in database")
            raise HTTPException(
                status_code=404,
                detail="User not found. Please ask them to /start the bot first."
            )

        print(f"‚úÖ User found: {result[0]} (first_name: {result[1]})")

        target_user_id = result[0]

        # Check if user is already in the project
        db.cursor.execute(
            "SELECT COUNT(*) FROM project_users WHERE project_id = ? AND user_id = ?",
            (project_id, target_user_id)
        )
        already_exists = db.cursor.fetchone()[0] > 0

        if already_exists:
            raise HTTPException(status_code=400, detail="User is already in this project")

        # Add user to project
        success = project_manager.add_user_to_project(project_id, target_user_id)

        if not success:
            raise HTTPException(status_code=400, detail="Failed to add user to project")

        return {"success": True, "message": f"User @{username} added to project"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error adding user to project: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/admin/projects")
async def create_project(
    project: ProjectCreate,
    user: dict = Depends(get_current_user)
):
    """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤)"""
    user_id = str(user.get('id'))

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    if user_id not in [str(admin_id) for admin_id in ADMIN_IDS]:
        raise HTTPException(status_code=403, detail="Access denied")

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–µ–∫—Ç
    new_project = project_manager.create_project(
        name=project.name,
        google_sheet_name=DEFAULT_GOOGLE_SHEETS_NAME,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        start_date=datetime.now().strftime("%Y-%m-%d"),
        end_date=project.deadline,
        target_views=project.target_views,
        geo=project.geo,
        kpi_views=project.kpi_views,
        allowed_platforms=project.allowed_platforms
    )

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–∑–¥–∞—Ç–µ–ª—è (–∞–¥–º–∏–Ω–∞) –≤ –ø—Ä–æ–µ–∫—Ç
    project_manager.add_user_to_project(new_project['id'], user_id)

    # –°–æ–∑–¥–∞–µ–º –ª–∏—Å—Ç –≤ Google Sheets, –µ—Å–ª–∏ project_sheets –¥–æ—Å—Ç—É–ø–µ–Ω
    if project_sheets:
        try:
            project_sheets.create_project_sheet(project.name)  # project - —ç—Ç–æ Pydantic –º–æ–¥–µ–ª—å!
            logger.info(f"‚úÖ –õ–∏—Å—Ç '{project.name}' —Å–æ–∑–¥–∞–Ω –≤ Google Sheets")
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ª–∏—Å—Ç–∞ –≤ Google Sheets: {e}")
            import traceback
            traceback.print_exc()

    return {"success": True, "project": new_project}

async def sync_project_from_sheets(project_id: str, project: dict):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SmartSyncService

    –ü—Ä–∏–º–µ–Ω—è–µ—Ç:
    - Safe number parsing (formatted numbers "1 000 000")
    - Platform-specific merge strategy (MAX for TikTok/Instagram, Sheets priority for FB/YT)
    - Protection for manual Facebook/YouTube edits
    """
    try:
        # üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º SmartSyncService –≤–º–µ—Å—Ç–æ —Ä—É—á–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
        from smart_sync import SmartSyncService

        sync_service = SmartSyncService(project_manager, project_sheets)
        result = sync_service.sync_project(project_id)

        if result.get('success'):
            logger.info(f"‚úÖ Auto-sync '{project['name']}': {result.get('snapshot_count', 0)} –æ–±–Ω–æ–≤–ª–µ–Ω–æ")

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Auto-sync error for '{project['name']}': {e}")

@app.get("/api/projects/{project_id}/analytics")
async def get_project_analytics(
    project_id: str,
    background_tasks: BackgroundTasks,
    user: dict = Depends(get_current_user),
    platform: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
):
    """–ü–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ –ø—Ä–æ–µ–∫—Ç—É —Å –∏—Å—Ç–æ—Ä–∏–µ–π (with Redis caching + background sync)"""
    user_id = str(user.get('id'))

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø
    user_projects = project_manager.get_user_projects(user_id)
    if not any(p['id'] == project_id for p in user_projects):
        raise HTTPException(status_code=403, detail="Access denied")

    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    # üöÄ REDIS CACHE: Check cache first
    cache_key = get_project_analytics_key(project_id)
    cached_data = cache.get(cache_key)
    if cached_data:
        # Validate cache: reject if shows 0 views but has profiles (data race/stale cache)
        total_views = cached_data.get('total_views', 0)
        total_profiles = cached_data.get('total_profiles', 0)

        if total_views == 0 and total_profiles > 0:
            logger.warning(f"‚ö†Ô∏è Invalid cache for project {project_id}: 0 views with {total_profiles} profiles - forcing sync")
            cache.delete(cache_key)  # Invalidate stale cache
        else:
            logger.info(f"üéØ Cache HIT for project {project_id} (valid data)")
            return cached_data

    # üîÑ –§–û–ù–û–í–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø: Google Sheets ‚Üí SQLite (–ù–ï –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç!)
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –í –§–û–ù–ï - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ª—É—á–∏—Ç –æ—Ç–≤–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω–æ!
    # –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤—è—Ç—Å—è —á–µ—Ä–µ–∑ 1-2 —Å–µ–∫ –≤ —Ñ–æ–Ω–µ, —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–∫–∞–∂–µ—Ç —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
    if project_sheets:
        background_tasks.add_task(sync_project_from_sheets, project_id, project)
        logger.info(f"üîÑ [Background] Sync task scheduled for project {project_id}")

    # üöÄ –ß–ò–¢–ê–ï–ú –î–ê–ù–ù–´–ï –¢–û–õ–¨–ö–û –ò–ó SQLite SNAPSHOTS (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ!)
    # Google Sheets —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ (auto-sync –≤—ã—à–µ), –∞ –º—ã —á–∏—Ç–∞–µ–º –∏–∑ –±–∞–∑—ã
    all_profiles = []

    logger.info(f"üìä Loading analytics from SQLite snapshots for project '{project['name']}'")
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã –∏–∑ SQLite
        sqlite_accounts = project_manager.get_project_social_accounts(project_id, platform)

        for account in sqlite_accounts:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π snapshot –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞
            snapshots = project_manager.get_account_snapshots(account['id'], limit=1)
            latest_snapshot = snapshots[0] if snapshots else {}

            # –ò–∑–≤–ª–µ–∫–∞–µ–º username –∏–∑ URL (—Ç–∞–∫ –∂–µ –∫–∞–∫ –¥–ª—è Sheets)
            url = account.get('profile_link', '').strip()
            username = None

            if '/@' in url:
                username = url.split('/@')[1].split('?')[0].split('/')[0]
            elif 'facebook.com' in url.lower() or 'fb.com' in url.lower():
                # Facebook: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç profile.php?id=...
                url_lower_local = url.lower()
                if 'profile.php?id=' in url_lower_local:
                    try:
                        import urllib.parse
                        parsed = urllib.parse.urlparse(url)
                        params = urllib.parse.parse_qs(parsed.query)
                        if 'id' in params:
                            username = params['id'][0]
                    except:
                        pass
                else:
                    # –û–±—ã—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                    clean_url = url.rstrip('/').split('?')[0]
                    # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —á–∞—Å—Ç–∏ –ø–æ—Å–ª–µ split
                    parts = [p for p in clean_url.split('/') if p]

                    if 'share' in parts:
                        idx = parts.index('share')
                        if idx + 1 < len(parts):
                            username = parts[idx + 1]
                    elif len(parts) > 0:
                        for part in reversed(parts):
                            if part and part not in ['facebook.com', 'www.facebook.com', 'fb.com', 'https:', 'http:']:
                                username = part
                                break

            # Fallback –Ω–∞ username –∏–∑ –±–∞–∑—ã –∏–ª–∏ telegram_user
            if not username:
                username = account.get('username') or account.get('telegram_user') or 'Unknown'
                # –£–±–∏—Ä–∞–µ–º @ –µ—Å–ª–∏ –µ—Å—Ç—å
                if username and username.startswith('@'):
                    username = username[1:]

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º total_videos_fetched –µ—Å–ª–∏ > 0, –∏–Ω–∞—á–µ fallback –Ω–∞ videos
            total_vids = latest_snapshot.get('total_videos_fetched', 0)
            videos_count = total_vids if total_vids > 0 else latest_snapshot.get('videos', 0)

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            last_update = "–ù–µ –æ–±–Ω–æ–≤–ª—è–ª–æ—Å—å"
            if latest_snapshot and latest_snapshot.get('snapshot_time'):
                try:
                    snapshot_time = latest_snapshot.get('snapshot_time')

                    # –ü–∞—Ä—Å–∏–º ISO —Ñ–æ—Ä–º–∞—Ç –∏ —É–±–∏—Ä–∞–µ–º timezone info –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    # SQLite —Ö—Ä–∞–Ω–∏—Ç –≤ UTC –±–µ–∑ timezone, –ø–æ—ç—Ç–æ–º—É –ø–∞—Ä—Å–∏–º –∫–∞–∫ naive datetime
                    if 'T' in snapshot_time:
                        # –§–æ—Ä–º–∞—Ç: "2025-12-08T22:14:44" –∏–ª–∏ "2025-12-08T22:14:44.123456"
                        dt_str = snapshot_time.split('.')[0]  # –£–±–∏—Ä–∞–µ–º –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã –µ—Å–ª–∏ –µ—Å—Ç—å
                        dt = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')
                    else:
                        # –§–æ—Ä–º–∞—Ç: "2025-12-08 22:14:44"
                        dt = datetime.strptime(snapshot_time.split('.')[0], '%Y-%m-%d %H:%M:%S')

                    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É —Å —Ç–µ–∫—É—â–∏–º –≤—Ä–µ–º–µ–Ω–µ–º (–æ–±–∞ naive datetime)
                    now = datetime.now()
                    diff = now - dt
                    total_seconds = int(diff.total_seconds())

                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º
                    if total_seconds < 0:
                        # –í—Ä–µ–º—è –≤ –±—É–¥—É—â–µ–º (–æ—à–∏–±–∫–∞ —á–∞—Å–æ–≤)
                        last_update = "–¢–æ–ª—å–∫–æ —á—Ç–æ"
                    elif total_seconds < 60:
                        # –ú–µ–Ω—å—à–µ –º–∏–Ω—É—Ç—ã
                        last_update = "–¢–æ–ª—å–∫–æ —á—Ç–æ"
                    elif total_seconds < 3600:  # –ú–µ–Ω—å—à–µ 1 —á–∞—Å–∞ (–¥–æ 59 –º–∏–Ω—É—Ç)
                        minutes = total_seconds // 60
                        last_update = f"{minutes} –º–∏–Ω. –Ω–∞–∑–∞–¥"
                    elif total_seconds < 86400:  # –û—Ç 1 —á–∞—Å–∞ –¥–æ 24 —á–∞—Å–æ–≤
                        hours = total_seconds // 3600
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —á–∞—Å: "1 —á. –Ω–∞–∑–∞–¥", "2 —á. –Ω–∞–∑–∞–¥", "23 —á. –Ω–∞–∑–∞–¥"
                        last_update = f"{hours} —á. –Ω–∞–∑–∞–¥"
                    else:  # –ë–æ–ª—å—à–µ —Å—É—Ç–æ–∫ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–∞—Ç—É
                        last_update = dt.strftime('%d.%m.%Y')

                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to parse snapshot_time '{snapshot_time}' for account {account.get('id')}: {e}")
                    last_update = "–ù–µ –æ–±–Ω–æ–≤–ª—è–ª–æ—Å—å"

            all_profiles.append({
                'telegram_user': account.get('telegram_user', 'Unknown'),
                'username': username,  # Username –∏–∑ —Å–æ—Ü —Å–µ—Ç–∏
                'url': url,
                'followers': latest_snapshot.get('followers', 0),
                'likes': latest_snapshot.get('likes', 0),
                'comments': latest_snapshot.get('comments', 0),
                'videos': videos_count,  # –í—Å–µ –≤–∏–¥–µ–æ (–∏—Å–ø–æ–ª—å–∑—É–µ–º total_videos_fetched –µ—Å–ª–∏ –µ—Å—Ç—å)
                'total_views': latest_snapshot.get('views', 0),
                'platform': account.get('platform', 'tiktok').lower(),
                'topic': account.get('topic', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
                'last_update': last_update  # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            })

        logger.info(f"‚úÖ Loaded {len(all_profiles)} profiles from SQLite for project '{project['name']}'")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Could not load accounts from SQLite: {e}")
        import traceback
        traceback.print_exc()

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
    users_stats = {}
    platform_stats = {"tiktok": 0, "instagram": 0, "facebook": 0, "youtube": 0}
    topic_stats = {}
    total_views = 0
    total_videos = 0
    total_profiles = len(all_profiles)

    for profile in all_profiles:
        telegram_user = profile['telegram_user']
        views = int(profile.get('total_views', 0) or 0)
        videos = int(profile.get('videos', 0) or 0)
        plat = profile['platform']
        topic = profile.get('topic', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')

        # –°—á–∏—Ç–∞–µ–º –í–°–ï –ø—Ä–æ—Å–º–æ—Ç—Ä—ã/–≤–∏–¥–µ–æ
        total_views += views
        total_videos += videos

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
        if telegram_user not in users_stats:
            users_stats[telegram_user] = {
                "total_views": 0,
                "platforms": {"tiktok": 0, "instagram": 0, "facebook": 0, "youtube": 0},
                "topics": {},
                "profiles_count": 0
            }

        users_stats[telegram_user]["total_views"] += views
        users_stats[telegram_user]["platforms"][plat] += views
        users_stats[telegram_user]["profiles_count"] += 1

        if topic:
            users_stats[telegram_user]["topics"][topic] = \
                users_stats[telegram_user]["topics"].get(topic, 0) + views

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º
        platform_stats[plat] += views

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º
        if topic:
            topic_stats[topic] = topic_stats.get(topic, 0) + views

    logger.info(f"üéØ FINAL ANALYTICS: total_views={total_views}, total_videos={total_videos}, total_profiles={total_profiles}")

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º start_date –∏ end_date –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã
    if not start_date:
        # –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
        start_date = project.get('start_date')
        # –ï—Å–ª–∏ –∏ –≤ –ø—Ä–æ–µ–∫—Ç–µ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º 30 –¥–Ω–µ–π –Ω–∞–∑–∞–¥
        if not start_date:
            start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            logger.warning(f"‚ö†Ô∏è Project {project_id} has no start_date, using 30 days ago: {start_date}")

    if not end_date:
        end_date = project.get('end_date') or datetime.now().strftime('%Y-%m-%d')

    # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –∏–∑ SQLite
    daily_history = project_manager.get_project_daily_history(project_id, start_date, end_date)

    # –ï—Å–ª–∏ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –≤ SQLite, —Å–æ–∑–¥–∞–µ–º —Ç–æ—á–∫–∏ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞
    history = daily_history.get("history", [])
    growth_24h = daily_history.get("growth_24h", 0)
    today = datetime.now().strftime('%Y-%m-%d')

    if len(history) == 0 and total_views > 0:
        # –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â—É—é —Ç–æ—á–∫—É
        history = [{
            "date": today,
            "views": total_views
        }]
        growth_24h = 0

        logger.warning(f"‚ö†Ô∏è No historical data available. Showing only current point: {today} with {total_views} views")
        logger.info(f"üí° To enable historical chart, add daily snapshots using POST /api/accounts/{{account_id}}/snapshot")
    else:
        # –ï—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è data –∏–∑ snapshots
        logger.info(f"üìä Loaded real history: {len(history)} days, growth_24h: {growth_24h}")

        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞ –ù–ï —Å–µ–≥–æ–¥–Ω—è - –¥–æ–±–∞–≤–ª—è–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é —Ç–æ—á–∫—É –∏–∑ Google Sheets
        if history and history[-1]['date'] != today and total_views > 0:
            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∏—Ä–æ—Å—Ç –∑–∞ 24—á –∫–∞–∫ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É —Å–µ–≥–æ–¥–Ω—è –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–æ–π
            last_day_views = history[-1]['views']
            growth_24h = total_views - last_day_views

            history.append({
                "date": today,
                "views": total_views  # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets!
            })

            logger.info(f"üìä Added today's dynamic point: {today} with {total_views} views (growth: +{growth_24h})")

    # –ì—Ä–∞—Ñ–∏–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã–µ (–Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–µ) –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–µ–∫—Ç–∞
    # chart_data = history (—Ñ–æ—Ä–º–∞—Ç: [{date, views}, ...] –≥–¥–µ views - —ç—Ç–æ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞)
    logger.info(f"üìä Chart data prepared: {len(history)} days (cumulative values)")

    # DEBUG: Log all_profiles before returning
    logger.info(f"üîç DEBUG FINAL all_profiles count: {len(all_profiles)}")
    for idx, prof in enumerate(all_profiles):
        logger.info(f"üîç DEBUG PROFILE[{idx}]: username='{prof.get('username')}', url='{prof.get('url')}', views={prof.get('total_views')}, platform='{prof.get('platform')}'")

    # Prepare response data
    response_data = {
        "project": project,
        "total_views": total_views,
        "total_videos": total_videos,
        "total_profiles": total_profiles,
        "platform_stats": platform_stats,
        "topic_stats": topic_stats,
        "users_stats": users_stats,
        "profiles": all_profiles,  # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –¥–ª—è –¥–∏–∞–≥—Ä–∞–º–º—ã –∞–∫–∫–∞—É–Ω—Ç–æ–≤
        "target_views": project['target_views'],
        "progress_percent": min(100, round((total_views / project['target_views'] * 100), 2)) if project['target_views'] > 0 else 0,
        "history": history,  # –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞)
        "chart_data": history,  # –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ (–Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞)
        "growth_24h": growth_24h,
        "backend_version": "v2.1_redis_cache"  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –≤–µ—Ä—Å–∏–∏ –±—ç–∫–µ–Ω–¥–∞
    }

    # üöÄ REDIS CACHE: Save to cache
    # Use longer TTL for finished projects (they don't change)
    is_finished = project.get('is_active') == 0 or project.get('is_active') == False
    ttl = TTL_FINISHED_PROJECT if is_finished else TTL_PROJECT_ANALYTICS
    cache.set(cache_key, response_data, ttl)
    logger.info(f"üíæ Cached project analytics for {project_id} (TTL: {ttl}s, finished: {is_finished})")

    return response_data

@app.get("/api/my-analytics")
async def get_my_analytics(
    background_tasks: BackgroundTasks,
    user: dict = Depends(get_current_user),
    project_id: Optional[str] = None
):
    """–ü–æ–ª—É—á–∏—Ç—å –ª–∏—á–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (with Redis caching + background sync)"""
    user_id = str(user.get('id'))
    username = user.get('username', '')
    telegram_user = f"@{username}" if username else user.get('first_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')

    # üöÄ REDIS CACHE: Check cache first (if project_id specified)
    if project_id:
        cache_key = get_user_analytics_key(user_id, project_id)
        cached_data = cache.get(cache_key)
        if cached_data:
            # Validate cache: reject if shows 0 views but has profiles
            total_views = cached_data.get('total_views', 0)
            total_profiles = len(cached_data.get('profiles', []))

            if total_views == 0 and total_profiles > 0:
                logger.warning(f"‚ö†Ô∏è Invalid cache for user {user_id} in project {project_id}: 0 views with {total_profiles} profiles - forcing sync")
                cache.delete(cache_key)  # Invalidate stale cache
            else:
                logger.info(f"üéØ Cache HIT for user {user_id} analytics in project {project_id} (valid data)")
                return cached_data

    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—Ä–æ–µ–∫—Ç, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–µ–º—É
    project_name = None
    if project_id:
        project = project_manager.get_project(project_id)
        if project:
            project_name = project['name']

            # üîÑ –§–û–ù–û–í–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø (–ù–ï –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç!)
            if project_sheets:
                background_tasks.add_task(sync_project_from_sheets, project_id, project)
                logger.info(f"üîÑ [Background] Sync task scheduled for user {user_id} analytics")

    # üöÄ –ß–ò–¢–ê–ï–ú –ü–†–û–§–ò–õ–ò –ò–ó SQLite SNAPSHOTS (—Ç–∞–∫ –∂–µ –∫–∞–∫ –≤ /api/projects/{project_id}/analytics)
    # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É "–í—Å–µ –ø—Ä–æ–µ–∫—Ç—ã" –∏ "–ú–æ–∏ –ø—Ä–æ–µ–∫—Ç—ã"
    profiles = []
    if project_id:
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ SQLite
            sqlite_accounts = project_manager.get_project_social_accounts(project_id, platform=None)

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º telegram_user –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º @ –µ—Å–ª–∏ –µ—Å—Ç—å)
            normalized_telegram_user = telegram_user.lstrip('@')

            logger.info(f"üîç [MyAnalytics] Looking for user: '{normalized_telegram_user}' in project {project_id}")
            logger.info(f"üîç [MyAnalytics] Found {len(sqlite_accounts)} total accounts in project")

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–µ–∫—É—â–µ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            for account in sqlite_accounts:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º telegram_user –∏–∑ –±–∞–∑—ã (—É–±–∏—Ä–∞–µ–º @ –µ—Å–ª–∏ –µ—Å—Ç—å)
                account_telegram_user = account.get('telegram_user', '').lstrip('@')

                logger.debug(f"üîç [MyAnalytics] Comparing: '{account_telegram_user}' == '{normalized_telegram_user}'")

                if account_telegram_user == normalized_telegram_user:
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π snapshot –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞
                    snapshots = project_manager.get_account_snapshots(account['id'], limit=1)
                    latest_snapshot = snapshots[0] if snapshots else {}

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º username –∏–∑ URL (—Ç–∞–∫ –∂–µ –∫–∞–∫ –¥–ª—è Sheets)
                    url = account.get('profile_link', '').strip()
                    username = None

                    if '/@' in url:
                        username = url.split('/@')[1].split('?')[0].split('/')[0]
                    elif 'facebook.com' in url.lower() or 'fb.com' in url.lower():
                        # Facebook: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç profile.php?id=...
                        url_lower_local = url.lower()
                        if 'profile.php?id=' in url_lower_local:
                            try:
                                import urllib.parse
                                parsed = urllib.parse.urlparse(url)
                                params = urllib.parse.parse_qs(parsed.query)
                                if 'id' in params:
                                    username = params['id'][0]
                            except:
                                pass
                        else:
                            # –û–±—ã—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                            clean_url = url.rstrip('/').split('?')[0]
                            parts = [p for p in clean_url.split('/') if p]

                            if 'share' in parts:
                                idx = parts.index('share')
                                if idx + 1 < len(parts):
                                    username = parts[idx + 1]
                            elif len(parts) > 0:
                                for part in reversed(parts):
                                    if part and part not in ['facebook.com', 'www.facebook.com', 'fb.com', 'https:', 'http:']:
                                        username = part
                                        break

                    # Fallback –Ω–∞ username –∏–∑ –±–∞–∑—ã –∏–ª–∏ telegram_user
                    if not username:
                        username = account.get('username') or account.get('telegram_user') or 'Unknown'
                        if username and username.startswith('@'):
                            username = username[1:]

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º total_videos_fetched –µ—Å–ª–∏ > 0, –∏–Ω–∞—á–µ fallback –Ω–∞ videos
                    total_vids = latest_snapshot.get('total_videos_fetched', 0)
                    videos_count = total_vids if total_vids > 0 else latest_snapshot.get('videos', 0)

                    profiles.append({
                        'telegram_user': account.get('telegram_user', 'Unknown'),
                        'username': username,
                        'url': url,
                        'followers': latest_snapshot.get('followers', 0),
                        'likes': latest_snapshot.get('likes', 0),
                        'comments': latest_snapshot.get('comments', 0),
                        'videos': videos_count,
                        'total_views': latest_snapshot.get('views', 0),
                        'platform': account.get('platform', 'tiktok').lower(),
                        'topic': account.get('topic', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                    })

            logger.info(f"‚úÖ [MyAnalytics] Found {len(profiles)} profiles for user '{normalized_telegram_user}'")
        except Exception as e:
            logger.error(f"‚ùå [MyAnalytics] Could not load user profiles from SQLite for project {project_id}: {e}")
            import traceback
            traceback.print_exc()

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    platform_stats = {"tiktok": 0, "instagram": 0, "facebook": 0, "youtube": 0, "threads": 0}
    topic_stats = {}
    total_views = 0
    total_videos = 0

    for profile in profiles:
        views = int(profile.get('total_views', 0) or 0)
        videos = int(profile.get('videos', 0) or 0)
        plat = profile['platform']
        topic = profile.get('topic', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')

        total_views += views
        total_videos += videos
        if plat in platform_stats:
            platform_stats[plat] += views

        if topic:
            topic_stats[topic] = topic_stats.get(topic, 0) + views

    # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω project_id, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–∞–∫ –≤ /api/projects/{project_id}/analytics
    if project_id and project:
        # –°–æ–∑–¥–∞–µ–º users_stats —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        users_stats = {
            telegram_user: {
                "total_views": total_views,
                "total_videos": total_videos,
                "profiles_count": len(profiles)
            }
        }

        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ö–û–ù–ö–†–ï–¢–ù–û–ì–û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø (–Ω–µ –≤—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞!)
        daily_history = project_manager.get_user_daily_history(project_id, telegram_user)

        # –ï—Å–ª–∏ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –≤ SQLite, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â—É—é —Ç–æ—á–∫—É
        history = daily_history.get("history", [])
        growth_24h = daily_history.get("growth_24h", 0)
        today = datetime.now().strftime('%Y-%m-%d')

        if len(history) == 0 and total_views > 0:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é —Ç–æ—á–∫—É —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            history = [{"date": today, "views": total_views}]
            growth_24h = 0  # –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ = –Ω–µ—Ç –ø—Ä–∏—Ä–æ—Å—Ç–∞
        else:
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞ –ù–ï —Å–µ–≥–æ–¥–Ω—è - –¥–æ–±–∞–≤–ª—è–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é —Ç–æ—á–∫—É
            if history and history[-1]['date'] != today and total_views > 0:
                last_day_views = history[-1]['views']
                growth_24h = total_views - last_day_views

                history.append({
                    "date": today,
                    "views": total_views  # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets!
                })

                logger.info(f"üìä [My Analytics] Added today's dynamic point: {today} with {total_views} views")

        # –í—ã—á–∏—Å–ª—è–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–∞—Ö (—Å—Ç–æ–ª–±–∏–∫–∏)
        daily_growth = []
        for i, day in enumerate(history):
            if i == 0:
                # –ü–µ—Ä–≤—ã–π –¥–µ–Ω—å - –ø—Ä–∏—Ä–æ—Å—Ç = –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –¥–Ω—è
                growth = day['views']
            else:
                # –û—Å—Ç–∞–ª—å–Ω—ã–µ –¥–Ω–∏ - —Ä–∞–∑–Ω–∏—Ü–∞ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –¥–Ω–µ–º
                growth = day['views'] - history[i-1]['views']

            daily_growth.append({
                "date": day['date'],
                "growth": max(0, growth)  # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç
            })

        logger.info(f"üìä [My Analytics] Daily growth calculated: {len(daily_growth)} days for chart")

        response_data = {
            "project": project,
            "total_views": total_views,
            "total_videos": total_videos,
            "total_profiles": len(profiles),
            "platform_stats": platform_stats,
            "topic_stats": topic_stats,
            "users_stats": users_stats,
            "profiles": profiles,  # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π –¥–ª—è –¥–∏–∞–≥—Ä–∞–º–º—ã –∞–∫–∫–∞—É–Ω—Ç–æ–≤
            "target_views": project['target_views'],
            "progress_percent": min(100, round((total_views / project['target_views'] * 100), 2)) if project['target_views'] > 0 else 0,
            "history": history,  # –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            "chart_data": daily_growth,  # –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç –¥–ª—è —Å—Ç–æ–ª–±–∏–∫–æ–≤ –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–∞—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
            "growth_24h": growth_24h,
            "backend_version": "v2.1_redis_cache"  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –≤–µ—Ä—Å–∏–∏ –±—ç–∫–µ–Ω–¥–∞
        }

        # üöÄ REDIS CACHE: Save user analytics to cache
        cache.set(cache_key, response_data, TTL_USER_ANALYTICS)
        logger.info(f"üíæ Cached user analytics for user {user_id} in project {project_id} (TTL: {TTL_USER_ANALYTICS}s)")

        return response_data

    # –ò–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–¥–ª—è –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)
    return {
        "total_views": total_views,
        "platform_stats": platform_stats,
        "topic_stats": topic_stats,
        "profiles_count": len(profiles)
    }

# ============ –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ============

@app.post("/api/admin/projects/{project_id}/bonus")
async def add_bonus(
    project_id: str,
    bonus: BonusCreate,
    user: dict = Depends(get_current_user)
):
    """–î–æ–±–∞–≤–∏—Ç—å –±–æ–Ω—É—Å –≤ –ø—Ä–æ–µ–∫—Ç (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤)"""
    user_id = user.get('id')

    # TODO: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–¥–º–∏–Ω–∞
    # if user_id not in ADMIN_IDS:
    #     raise HTTPException(status_code=403, detail="Admin access required")

    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –±–æ–Ω—É—Å–æ–≤ –≤ –ë–î
    # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    return {
        "success": True,
        "message": "Bonus added successfully",
        "bonus": bonus.dict()
    }

@app.post("/api/admin/projects/{project_id}/update-timestamp")
async def update_project_timestamp(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """
    –û–±–Ω–æ–≤–∏—Ç—å timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ '–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã' (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤)

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ –ø–æ–ª–µ last_admin_update –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –º–µ–∂–¥—É —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏.
    """
    user_id = user.get('id')

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–¥–º–∏–Ω–∞
    if user_id not in ADMIN_IDS:
        raise HTTPException(status_code=403, detail="Admin access required")

    try:
        logger.info(f"üîÑ [Timestamp] –ù–∞—á–∏–Ω–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ timestamp –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_id}, –∞–¥–º–∏–Ω {user_id}")

        # –û–±–Ω–æ–≤–ª—è–µ–º timestamp –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        success = project_manager.update_project_admin_timestamp(project_id)

        logger.info(f"üîç [Timestamp] –†–µ–∑—É–ª—å—Ç–∞—Ç update_project_admin_timestamp: {success}")

        if not success:
            logger.error(f"‚ùå [Timestamp] update_project_admin_timestamp –≤–µ—Ä–Ω—É–ª False –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_id}")
            raise HTTPException(status_code=500, detail="Failed to update timestamp in database")

        # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–µ—à –ø—Ä–æ–µ–∫—Ç–∞
        cache.invalidate_project(project_id)

        logger.info(f"‚úÖ [Timestamp] Timestamp –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_id} –∞–¥–º–∏–Ω–æ–º {user_id}")

        return {
            "success": True,
            "message": "Timestamp updated successfully",
            "timestamp": datetime.utcnow().isoformat()
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå [Timestamp] –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ timestamp –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_id}: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Exception: {str(e)}")

@app.post("/api/admin/clear-snapshots")
async def clear_all_snapshots(
    user: dict = Depends(get_current_user)
):
    """–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ snapshots –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤)"""
    user_id = user.get('id')

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–¥–º–∏–Ω–∞
    if user_id not in ADMIN_IDS:
        raise HTTPException(status_code=403, detail="Admin access required")

    try:
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ snapshots –∏ daily stats
        project_manager.db.cursor.execute('DELETE FROM account_snapshots')
        deleted_snapshots = project_manager.db.cursor.rowcount

        project_manager.db.cursor.execute('DELETE FROM account_daily_stats')
        deleted_daily_stats = project_manager.db.cursor.rowcount

        project_manager.db.conn.commit()

        logger.info(f"üóëÔ∏è Cleared {deleted_snapshots} snapshots and {deleted_daily_stats} daily stats by admin user {user_id}")

        return {
            "success": True,
            "message": f"Cleared {deleted_snapshots} snapshots and {deleted_daily_stats} daily stats",
            "deleted_snapshots": deleted_snapshots,
            "deleted_daily_stats": deleted_daily_stats
        }
    except Exception as e:
        logger.error(f"‚ùå Error clearing snapshots: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============ API –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã–º–∏ –∞–∫–∫–∞—É–Ω—Ç–∞–º–∏ ============

@app.post("/api/projects/{project_id}/accounts")
async def add_social_account(
    project_id: str,
    account: SocialAccountCreate,
    user: dict = Depends(get_current_user)
):
    """–î–æ–±–∞–≤–∏—Ç—å —Å–æ—Ü–∏–∞–ª—å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç –≤ –ø—Ä–æ–µ–∫—Ç"""

    logger.info("üöÄ MAIN.PY add_social_account called!")

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞
    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–∞–∑—Ä–µ—à–µ–Ω–∞ –ª–∏ —ç—Ç–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –≤ –ø—Ä–æ–µ–∫—Ç–µ
    allowed_platforms = project.get('allowed_platforms', {})
    if not allowed_platforms.get(account.platform.lower(), False):
        logger.warning(f"‚ö†Ô∏è Platform {account.platform} not allowed in project {project_id}")
        raise HTTPException(
            status_code=400,
            detail=f"–î–æ–±–∞–≤—å—Ç–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –∏–∑ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö"
        )

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ –∞–∫–∫–∞—É–Ω—Ç —Å —Ç–∞–∫–æ–π —Å—Å—ã–ª–∫–æ–π
    existing_accounts = project_manager.get_project_social_accounts(project_id)
    for existing in existing_accounts:
        if existing.get('profile_link', '').strip() == account.profile_link.strip():
            logger.warning(f"‚ö†Ô∏è Duplicate account detected: {account.profile_link}")
            raise HTTPException(
                status_code=400,
                detail=f"–≠—Ç–æ—Ç –∞–∫–∫–∞—É–Ω—Ç —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –ø—Ä–æ–µ–∫—Ç"
            )

    # Safely get telegram_user (may not be present)
    telegram_user_from_frontend = getattr(account, 'telegram_user', None)
    logger.info(f"üîç account.telegram_user = {repr(telegram_user_from_frontend)}")

    # Extract display name from frontend OR initData
    if telegram_user_from_frontend and telegram_user_from_frontend.strip():
        display_name = telegram_user_from_frontend.strip()
        logger.info(f"‚úÖ Using telegram_user from FRONTEND: '{display_name}'")
    else:
        # Fallback to initData
        tg_username = user.get('username')
        first_name = user.get('first_name', '')
        last_name = user.get('last_name', '')

        if tg_username:
            display_name = f"@{tg_username}"
        elif first_name or last_name:
            display_name = f"{first_name} {last_name}".strip()
        else:
            display_name = f"ID:{user.get('id')}"

        logger.info(f"‚ö†Ô∏è Frontend value empty, using initData: '{display_name}'")

    logger.info(f"‚úÖ FINAL USER: {display_name}")

    # –î–æ–±–∞–≤–ª—è–µ–º –∞–∫–∫–∞—É–Ω—Ç –≤ –ë–î
    result = project_manager.add_social_account_to_project(
        project_id=project_id,
        platform=account.platform,
        username=account.username,
        profile_link=account.profile_link,
        status=account.status,
        topic=account.topic,
        telegram_user=display_name
    )

    if not result:
        raise HTTPException(status_code=400, detail="Failed to add account")

    # –î–æ–±–∞–≤–ª—è–µ–º –≤ Google Sheets (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if project_sheets:
        try:
            # –°–æ–∑–¥–∞–µ–º –ª–∏—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            project_sheets.create_project_sheet(project['name'])

            # –ü–∞—Ä—Å–∏–º username –∏–∑ URL –∏—Å–ø–æ–ª—å–∑—É—è —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ project_sheets_manager
            parsed_username = project_sheets._parse_username_from_url(account.profile_link)
            logger.info(f"üìä Parsed username from URL: '{parsed_username}' (original: '{account.username}')")

            # –î–æ–±–∞–≤–ª—è–µ–º –∞–∫–∫–∞—É–Ω—Ç –≤ –ª–∏—Å—Ç –° TELEGRAM USERNAME!
            logger.info(f"üìä Sending to Sheets: telegram_user = '{display_name}'")
            project_sheets.add_account_to_sheet(project['name'], {
                'username': parsed_username,  # ‚Üê –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π username
                'profile_link': account.profile_link,
                'followers': 0,
                'likes': 0,
                'comments': 0,
                'videos': 0,
                'views': 0,
                'status': account.status,
                'topic': account.topic,
                'platform': account.platform,
                'telegram_user': display_name
            })
            logger.info(f"‚úÖ Added to Sheets: {parsed_username} by {display_name}")
        except Exception as e:
            logger.error(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ Google Sheets: {e}")

    return {"success": True, "account": result}

@app.get("/api/projects/{project_id}/accounts")
async def get_project_accounts(
    project_id: str,
    platform: Optional[str] = None,
    user: dict = Depends(get_current_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ (–≤–∏–¥–µ–æ/–ø—Ä–æ—Å–º–æ—Ç—Ä—ã)"""
    accounts = project_manager.get_project_social_accounts(project_id, platform)

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–µ–∫—Ç –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ Google Sheets
    project = project_manager.get_project(project_id)

    # –û–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏–∑ Google Sheets –∏–ª–∏ SQLite
    enriched_accounts = []

    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets
    sheets_data = {}
    if project and project_sheets:
        try:
            accounts_data = project_sheets.get_project_accounts(project['name'])
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –ø–æ —Å—Å—ã–ª–∫–∞–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            for acc_data in accounts_data:
                link = acc_data.get('Link', '')
                sheets_data[link] = {
                    'videos': int(acc_data.get('Videos', 0) or 0),
                    'views': int(acc_data.get('Views', 0) or 0)
                }
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not load metrics from sheets: {e}")

    # –û–±–æ–≥–∞—â–∞–µ–º –∫–∞–∂–¥—ã–π –∞–∫–∫–∞—É–Ω—Ç
    for account in accounts:
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –≤ Google Sheets
        profile_link = account.get('profile_link', '')
        metrics = sheets_data.get(profile_link)

        # –ï—Å–ª–∏ –Ω–µ—Ç –≤ Sheets, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ snapshot
        if not metrics:
            snapshots = project_manager.get_account_snapshots(account['id'], limit=1)
            latest_snapshot = snapshots[0] if snapshots else {}
            metrics = {
                'videos': latest_snapshot.get('videos', 0),
                'views': latest_snapshot.get('views', 0)
            }

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫ –∞–∫–∫–∞—É–Ω—Ç—É
        enriched_account = {**account, **metrics}
        enriched_accounts.append(enriched_account)

    return {"success": True, "accounts": enriched_accounts}

@app.post("/api/projects/{project_id}/import_from_sheets")
async def import_from_sheets(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets (Sheets –∫–∞–∫ Master DB)"""
    logger.info(f"üîÑ Starting import from Sheets for project {project_id}")

    # Get project
    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    if not project_sheets:
        raise HTTPException(status_code=503, detail="Google Sheets not available")

    try:
        # Read data from Google Sheets
        sheet_records = project_sheets.read_project_sheet(project['name'])
        logger.info(f"üìä Found {len(sheet_records)} records in Google Sheets")

        # Get all project accounts from SQLite
        sqlite_accounts = project_manager.get_project_social_accounts(project_id)

        # Create username -> account_id mapping
        username_to_id = {acc['username']: acc['id'] for acc in sqlite_accounts}

        updated_count = 0
        skipped_count = 0

        for record in sheet_records:
            # Extract data from Sheet record
            # Headers: @Username, Link, Followers, Likes, Following, Videos, Views, Last Update, Status, –¢–µ–º–∞—Ç–∏–∫–∞
            username = record.get('Link', '').split('@')[-1].split('?')[0].strip('/')
            if not username:
                username = record.get('@Username', '').strip('@')

            followers = int(record.get('Followers', 0) or 0)
            likes = int(record.get('Likes', 0) or 0)
            videos = int(record.get('Videos', 0) or 0)
            views = int(record.get('Views', 0) or 0)

            # Find account in SQLite
            account_id = username_to_id.get(username)

            if account_id:
                # Create snapshot with metrics from Sheets
                success = project_manager.add_account_snapshot(
                    account_id=account_id,
                    followers=followers,
                    likes=likes,
                    comments=0,  # Not in Sheets
                    videos=videos,
                    views=views
                )
                if success:
                    updated_count += 1
                    logger.info(f"‚úÖ Updated {username}: {followers} followers, {views} views")
            else:
                skipped_count += 1
                logger.info(f"‚ö†Ô∏è Account {username} not found in SQLite, skipping")

        logger.info(f"‚úÖ Import completed: {updated_count} updated, {skipped_count} skipped")

        return {
            "success": True,
            "updated": updated_count,
            "skipped": skipped_count,
            "total": len(sheet_records)
        }

    except Exception as e:
        logger.error(f"‚ùå Import error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Import failed: {str(e)}")

@app.get("/api/projects/{project_id}/refresh_stats/stream")
async def refresh_stats_stream(
    project_id: str,
    init_data: str = None
):
    """SSE endpoint –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é —á–µ—Ä–µ–∑ query –ø–∞—Ä–∞–º–µ—Ç—Ä (EventSource –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç headers)
    if not init_data:
        raise HTTPException(status_code=401, detail="init_data required")

    try:
        user = validate_telegram_init_data(init_data)
        logger.info(f"üì° Client connected to progress stream for project {project_id} (user: {user.get('id')})")
    except HTTPException:
        raise HTTPException(status_code=401, detail="Invalid init_data")

    async def event_generator():
        """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–æ–±—ã—Ç–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        try:
            last_progress = None
            iteration = 0
            while True:
                iteration += 1
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
                current_progress = dict(refresh_progress.get(project_id, {}))

                logger.info(f"üì° SSE iteration {iteration}: current_progress = {current_progress}")

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–∑–º–µ–Ω–∏–ª—Å—è
                if current_progress != last_progress:
                    data = json.dumps(current_progress)
                    logger.info(f"üì§ Sending SSE update: {data}")
                    yield f"data: {data}\n\n"
                    last_progress = current_progress.copy()

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ - –≤—Å–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
                    all_done = all(
                        stats['processed'] >= stats['total']
                        for stats in current_progress.values()
                        if stats['total'] > 0
                    )

                    logger.info(f"üîç All done check: {all_done}, platforms: {len(current_progress)}")

                    if all_done and len(current_progress) > 0:
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ
                        logger.info(f"üì§ Sending completion event")
                        yield f"data: {json.dumps({'status': 'completed'})}\n\n"
                        logger.info(f"‚úÖ Progress stream completed for project {project_id}")
                        break

                # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                await asyncio.sleep(0.5)

        except asyncio.CancelledError:
            logger.info(f"‚ùå Client disconnected from progress stream for project {project_id}")
            # –û—á–∏—â–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏
            if project_id in refresh_progress:
                del refresh_progress[project_id]

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # –û—Ç–∫–ª—é—á–∞–µ–º –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è Nginx
        }
    )

@app.get("/api/projects/{project_id}/refresh_progress")
async def get_refresh_progress(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    progress = dict(refresh_progress.get(project_id, {}))
    logger.info(f"üìä Get progress for project {project_id}: {progress}")
    return {
        "success": True,
        "progress": progress
    }

@app.post("/api/projects/{project_id}/refresh_stats")
async def refresh_project_stats(
    project_id: str,
    request: RefreshStatsRequest,
    background_tasks: BackgroundTasks,
    user: dict = Depends(get_current_user)
):
    """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º —á–µ—Ä–µ–∑ API"""
    logger.info(f"üîÑ Starting stats refresh for project {project_id}, platforms: {request.platforms}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å - –∞–¥–º–∏–Ω
    if user['id'] not in ADMIN_IDS:
        raise HTTPException(status_code=403, detail="Only admins can refresh stats")

    # üßπ REDIS CACHE: Invalidate cache for this project (stats will be updated)
    cache.invalidate_project(project_id)
    logger.info(f"üßπ Invalidated cache for project {project_id} before refresh")

    # –ù–ï–ú–ï–î–õ–ï–ù–ù–ê–Ø –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–¥–æ –ª—é–±—ã—Ö –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π!)
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫–∫–∞—É–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
        accounts = project_manager.get_project_social_accounts(project_id)
        logger.info(f"üìä Found {len(accounts)} accounts in project")

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
        platform_stats = {}
        for platform in request.platforms:
            if request.platforms[platform]:
                count = sum(1 for acc in accounts if acc.get('platform', 'tiktok').lower() == platform)
                platform_stats[platform] = {'total': count, 'processed': 0, 'updated': 0, 'failed': 0}

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –≥–ª–æ–±–∞–ª—å–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –°–†–ê–ó–£
        refresh_progress[project_id] = platform_stats.copy()
        logger.info(f"üîß IMMEDIATELY initialized refresh_progress[{project_id}] = {refresh_progress[project_id]}")

    except Exception as e:
        logger.error(f"‚ùå Failed to initialize progress: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to initialize progress: {str(e)}")

    # –¢–µ–ø–µ—Ä—å –¥–µ–ª–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    if not project_sheets:
        raise HTTPException(status_code=503, detail="Google Sheets not available")

    if not tiktok_api and not instagram_api and not facebook_api:
        raise HTTPException(status_code=503, detail="Stats API clients not available")

    # –ü–æ–ª—É—á–∞–µ–º KPI –ø—Ä–æ–µ–∫—Ç–∞
    kpi_views = project.get('kpi_views', 1000)
    logger.info(f"üìä Project KPI: >= {kpi_views:,} –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –Ω–∞ –≤–∏–¥–µ–æ")

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ
    background_tasks.add_task(
        process_accounts_background,
        project_id=project_id,
        project=project,
        accounts=accounts,
        platforms=request.platforms,
        platform_stats=platform_stats,
        kpi_views=kpi_views,
        date_from=request.date_from,
        date_to=request.date_to
    )

    logger.info(f"‚úÖ Background task started for project {project_id}")

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö –°–†–ê–ó–£, —á—Ç–æ–±—ã polling –º–æ–≥ –Ω–∞—á–∞—Ç—å –ø–æ–ª—É—á–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
    return {
        "success": True,
        "message": "Stats refresh started in background",
        "total_accounts": len(accounts)
    }


def process_accounts_background(
    project_id: str,
    project: dict,
    accounts: list,
    platforms: dict,
    platform_stats: dict,
    kpi_views: int,
    date_from: Optional[str] = None,
    date_to: Optional[str] = None
):
    """
    –§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

    :param date_from: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞ (YYYY-MM-DD) - —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –ø–æ—Å–ª–µ —ç—Ç–æ–π –¥–∞—Ç—ã
    :param date_to: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∞ (YYYY-MM-DD) - —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –¥–æ —ç—Ç–æ–π –¥–∞—Ç—ã
    """
    import time

    logger.info(f"\n{'='*70}")
    logger.info(f"üöÄ BACKGROUND TASK STARTED FOR PROJECT {project_id}")
    logger.info(f"üìä –ü–†–û–ì–†–ï–°–°-–ë–ê–† –û–ë–ù–û–í–õ–ï–ù–ò–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ò")
    logger.info(f"{'='*70}")
    for platform, stats in platform_stats.items():
        logger.info(f"   {platform.upper()}: 0/{stats['total']} –∞–∫–∫–∞—É–Ω—Ç–æ–≤")
    if date_from or date_to:
        logger.info(f"üìÖ –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–∞–º: —Å {date_from or '–Ω–∞—á–∞–ª–∞'} –ø–æ {date_to or '—Å–µ–≥–æ–¥–Ω—è'}")
    logger.info(f"{'='*70}\n")

    updated_count = 0
    failed_count = 0
    errors = []

    for account in accounts:
        platform = account.get('platform', 'tiktok').lower()
        profile_link = account.get('profile_link', '')
        username = account.get('username', '')
        status = account.get('status', '').upper()

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        if not platforms.get(platform, False):
            logger.info(f"‚è≠Ô∏è Skipping {platform} account {username} (platform not selected)")
            continue

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º OLD
        if status == 'OLD':
            logger.info(f"‚è≠Ô∏è Skipping {platform} account {username} (status: OLD)")
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ processed –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            if platform in platform_stats:
                platform_stats[platform]['processed'] += 1
                refresh_progress[project_id][platform] = platform_stats[platform].copy()
            continue

        logger.info(f"üîÑ Updating {platform} account: {username}")

        try:
            stats = None

            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã (—Å KPI –∏ –¥–∞—Ç–∞–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
            if platform == 'tiktok' and tiktok_api:
                stats = tiktok_api.get_tiktok_data(profile_link, kpi_views=kpi_views, date_from=date_from, date_to=date_to)
            elif platform == 'instagram' and instagram_api:
                stats = instagram_api.get_instagram_data(profile_link, kpi_views=kpi_views, date_from=date_from, date_to=date_to)
            elif platform == 'facebook' and facebook_api:
                # Facebook –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥—Ä—É–≥—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö (Reels API)
                result = facebook_api.get_page_reels(profile_link, kpi_views=kpi_views, date_from=date_from, date_to=date_to)
                if result.get('success'):
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç Facebook –≤ –æ–±—â–∏–π —Ñ–æ—Ä–º–∞—Ç
                    stats = {
                        'total_views': result.get('total_views', 0),
                        'total_likes': result.get('total_likes', 0),
                        'videos': result.get('total_videos', 0),
                        'reels': result.get('total_videos', 0),
                        'total_videos_fetched': result.get('total_videos', 0),
                        'total_reels_fetched': result.get('total_videos', 0),
                        'followers': 0,  # Facebook API –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç followers –≤ Reels API
                        'likes': result.get('total_likes', 0)
                    }
                else:
                    stats = None
                    logger.error(f"‚ùå Facebook API error: {result.get('error', 'Unknown error')}")
            else:
                logger.warning(f"‚ö†Ô∏è Platform {platform} not supported yet")
                if platform in platform_stats:
                    platform_stats[platform]['processed'] += 1
                    platform_stats[platform]['failed'] += 1
                    # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
                    refresh_progress[project_id][platform] = platform_stats[platform].copy()
                continue

            if stats:
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤ Google Sheets
                stats_dict = {
                    'followers': stats.get('followers', 0),
                    'likes': stats.get('likes', stats.get('total_likes', 0)),
                    'videos': stats.get('videos', stats.get('reels', 0)),
                    'views': stats.get('total_views', 0),
                    'comments': 0  # –ù–µ –≤—Å–µ API –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                }
                project_sheets.update_account_stats(
                    project_name=project['name'],
                    username=username,
                    stats=stats_dict,
                    profile_link=profile_link  # –ü–µ—Ä–µ–¥–∞–µ–º URL –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ Sheets
                )

                # –°–æ–∑–¥–∞–µ–º snapshot –≤ SQLite
                project_manager.add_account_snapshot(
                    account_id=account['id'],
                    followers=stats.get('followers', 0),
                    likes=stats.get('likes', stats.get('total_likes', 0)),
                    comments=0,
                    videos=stats.get('videos', stats.get('reels', 0)),  # –í–∏–¥–µ–æ –ø—Ä–æ—à–µ–¥—à–∏–µ KPI
                    views=stats.get('total_views', 0),
                    total_videos_fetched=stats.get('total_videos_fetched', stats.get('total_reels_fetched', 0))  # –í—Å–µ –≤–∏–¥–µ–æ
                )

                updated_count += 1

                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                if platform in platform_stats:
                    platform_stats[platform]['processed'] += 1
                    platform_stats[platform]['updated'] += 1
                    # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
                    refresh_progress[project_id][platform] = platform_stats[platform].copy()
                    logger.info(f"üîÑ Updated refresh_progress[{project_id}][{platform}] = {refresh_progress[project_id][platform]}")

                logger.info(f"‚úÖ Updated {username}: {stats.get('total_views', 0)} views")

                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                logger.info(f"\n{'='*70}")
                logger.info(f"üìä –ü–†–û–ì–†–ï–°–° –û–ë–ù–û–í–õ–ï–ù–ò–Ø:")
                logger.info(f"{'='*70}")
                for plt, pstats in platform_stats.items():
                    progress_percent = (pstats['processed'] / pstats['total'] * 100) if pstats['total'] > 0 else 0
                    logger.info(f"   {plt.upper()}: {pstats['processed']}/{pstats['total']} ({progress_percent:.0f}%) | ‚úÖ {pstats['updated']} | ‚ùå {pstats['failed']}")
                logger.info(f"{'='*70}\n")

                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∞–∫–∫–∞—É–Ω—Ç–∞–º–∏ (—É–º–µ–Ω—å—à–∏–ª–∏ —Å 2 –¥–æ 1 —Å–µ–∫)
                time.sleep(1)

        except Exception as e:
            failed_count += 1

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            if platform in platform_stats:
                platform_stats[platform]['processed'] += 1
                platform_stats[platform]['failed'] += 1
                # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
                refresh_progress[project_id][platform] = platform_stats[platform].copy()

            error_msg = f"Failed to update {username}: {str(e)}"
            errors.append(error_msg)
            logger.error(f"‚ùå {error_msg}")

            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏
            logger.info(f"\n{'='*70}")
            logger.info(f"üìä –ü–†–û–ì–†–ï–°–° –û–ë–ù–û–í–õ–ï–ù–ò–Ø:")
            logger.info(f"{'='*70}")
            for plt, pstats in platform_stats.items():
                progress_percent = (pstats['processed'] / pstats['total'] * 100) if pstats['total'] > 0 else 0
                logger.info(f"   {plt.upper()}: {pstats['processed']}/{pstats['total']} ({progress_percent:.0f}%) | ‚úÖ {pstats['updated']} | ‚ùå {pstats['failed']}")
            logger.info(f"{'='*70}\n")

            continue

    logger.info(f"‚úÖ Stats refresh completed: {updated_count} updated, {failed_count} failed")

    # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    logger.info(f"\n{'='*70}")
    logger.info(f"üìä –ò–¢–û–ì–û–í–´–ô –ü–†–û–ì–†–ï–°–°:")
    logger.info(f"{'='*70}")
    for plt, pstats in platform_stats.items():
        logger.info(f"   {plt.upper()}: {pstats['total']} –∞–∫–∫–∞—É–Ω—Ç–æ–≤ | ‚úÖ {pstats['updated']} —É—Å–ø–µ—à–Ω–æ | ‚ùå {pstats['failed']} –æ—à–∏–±–æ–∫")
    logger.info(f"{'='*70}\n")

    logger.info(f"üèÅ BACKGROUND TASK COMPLETED FOR PROJECT {project_id}")

@app.post("/api/projects/{project_id}/migrate_platform_column")
async def migrate_platform_column(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """–î–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É Platform –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π Google Sheet –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ URL"""
    logger.info(f"üîÑ Starting platform column migration for project {project_id}")

    # Get project
    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    if not project_sheets:
        raise HTTPException(status_code=503, detail="Google Sheets not available")

    try:
        import gspread
        worksheet = project_sheets.spreadsheet.worksheet(project['name'])

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ –∫–æ–ª–æ–Ω–∫–∞ Platform
        headers = worksheet.row_values(1)
        logger.info(f"üìä Current headers: {headers}")

        if 'Platform' in headers:
            logger.info("‚úÖ Platform column already exists")
            return {"success": True, "message": "Platform column already exists"}

        # –í—Å—Ç–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É Platform –ø–æ—Å–ª–µ Link (–ø–æ–∑–∏—Ü–∏—è C)
        worksheet.insert_cols([[]], col=3, value_input_option='RAW')

        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        worksheet.update_cell(1, 3, 'Platform')

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏
        all_rows = worksheet.get_all_values()

        updated_count = 0
        # –ù–∞—á–∏–Ω–∞–µ–º —Å–æ 2-–π —Å—Ç—Ä–æ–∫–∏ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏)
        for row_idx, row in enumerate(all_rows[1:], start=2):
            if len(row) < 2:  # –ù–µ—Ç Link
                continue

            url = row[1].strip().lower()  # Link –≤ –∫–æ–ª–æ–Ω–∫–µ B
            platform = 'tiktok'  # Default

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –ø–æ URL
            if 'tiktok.com' in url:
                platform = 'tiktok'
            elif 'instagram.com' in url:
                platform = 'instagram'
            elif 'facebook.com' in url or 'fb.com' in url:
                platform = 'facebook'
            elif 'youtube.com' in url or 'youtu.be' in url:
                platform = 'youtube'
            elif 'threads.net' in url:
                platform = 'threads'

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –≤ –∫–æ–ª–æ–Ω–∫—É C
            worksheet.update_cell(row_idx, 3, platform)
            updated_count += 1
            logger.info(f"‚úÖ Row {row_idx}: {url[:50]} -> {platform}")

        logger.info(f"‚úÖ Migration completed: updated {updated_count} rows")

        return {
            "success": True,
            "updated": updated_count,
            "message": f"Platform column added and {updated_count} rows updated"
        }

    except gspread.exceptions.WorksheetNotFound:
        raise HTTPException(status_code=404, detail=f"Worksheet {project['name']} not found")
    except Exception as e:
        logger.error(f"‚ùå Migration error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Migration failed: {str(e)}")

@app.post("/api/projects/{project_id}/migrate_username_column")
async def migrate_username_column(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """–î–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É Username –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π Google Sheet –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–æ–º –∏–∑ Link"""
    logger.info(f"üîÑ Starting username column migration for project {project_id}")

    # Get project
    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    if not project_sheets:
        raise HTTPException(status_code=503, detail="Google Sheets not available")

    try:
        success = project_sheets.migrate_username_column(project['name'])

        if success:
            return {
                "success": True,
                "message": f"Username column migration completed for project {project['name']}"
            }
        else:
            raise HTTPException(status_code=500, detail="Migration failed")

    except Exception as e:
        logger.error(f"‚ùå Username migration error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Username migration failed: {str(e)}")

@app.post("/api/migrate_all_usernames")
async def migrate_all_usernames():
    """–ú–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É Username –¥–ª—è –í–°–ï–• –ø—Ä–æ–µ–∫—Ç–æ–≤ (–±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏, –¥–ª—è –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)"""
    logger.info("üîÑ Starting migration for ALL projects")

    if not project_sheets:
        raise HTTPException(status_code=503, detail="Google Sheets not available")

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ª–∏—Å—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü–µ
    try:
        all_sheets = project_sheets.spreadsheet.worksheets()
        results = []

        for sheet in all_sheets:
            project_name = sheet.title
            logger.info(f"üîÑ Migrating project: {project_name}")

            try:
                success = project_sheets.migrate_username_column(project_name)
                results.append({
                    "project": project_name,
                    "success": success,
                    "message": "Migration completed" if success else "Migration failed"
                })
            except Exception as e:
                logger.error(f"‚ùå Error migrating {project_name}: {e}")
                results.append({
                    "project": project_name,
                    "success": False,
                    "error": str(e)
                })

        logger.info(f"‚úÖ Migration completed for {len(results)} projects")

        return {
            "success": True,
            "total_projects": len(results),
            "results": results
        }

    except Exception as e:
        logger.error(f"‚ùå Migration error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Migration failed: {str(e)}")

@app.post("/api/save_daily_snapshots")
@app.post("/api/save_hourly_snapshots")  # Alias –¥–ª—è —á–∞—Å–æ–≤–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
async def save_daily_snapshots(cron_secret: Optional[str] = None):
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–Ω–∏–º–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –∏–∑ Google Sheets
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å —á–µ—Ä–µ–∑ –≤–Ω–µ—à–Ω–∏–π cron (cron-job.org, uptimerobot –∏ —Ç.–¥.)

    Optional: –¥–æ–±–∞–≤—å ?cron_secret=YOUR_SECRET –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞—â–∏—Ç—ã
    """
    logger.info("üìä Starting hourly snapshots save...")

    if not project_sheets:
        raise HTTPException(status_code=503, detail="Google Sheets not available")

    results = {
        "total_projects": 0,
        "total_accounts": 0,
        "saved_snapshots": 0,
        "errors": []
    }

    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø—Ä–æ–µ–∫—Ç—ã
        all_projects = project_manager.get_all_projects()
        results["total_projects"] = len(all_projects)

        for project in all_projects:
            project_id = project['id']
            project_name = project['name']

            logger.info(f"üìä Processing project: {project_name}")

            try:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets
                accounts_data = project_sheets.get_project_accounts(project_name)

                for account_data in accounts_data:
                    results["total_accounts"] += 1

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    profile_link = account_data.get('Link', '').strip()
                    if not profile_link:
                        continue

                    # –ù–∞—Ö–æ–¥–∏–º –∞–∫–∫–∞—É–Ω—Ç –≤ SQLite –ø–æ profile_link
                    sqlite_accounts = project_manager.get_project_social_accounts(project_id)
                    matching_account = next((acc for acc in sqlite_accounts if acc['profile_link'] == profile_link), None)

                    if not matching_account:
                        logger.warning(f"‚ö†Ô∏è Account not found in SQLite: {profile_link}")
                        continue

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º snapshot
                    success = project_manager.add_account_snapshot(
                        account_id=matching_account['id'],
                        followers=int(account_data.get('Followers', 0) or 0),
                        likes=int(account_data.get('Likes', 0) or 0),
                        comments=0,  # –ù–µ—Ç –≤ Sheets
                        videos=int(account_data.get('Videos', 0) or 0),
                        views=int(account_data.get('Views', 0) or 0)
                    )

                    if success:
                        results["saved_snapshots"] += 1
                    else:
                        results["errors"].append(f"Failed to save snapshot for {profile_link}")

            except Exception as e:
                error_msg = f"Error processing project {project_name}: {str(e)}"
                logger.error(f"‚ùå {error_msg}")
                results["errors"].append(error_msg)

        logger.info(f"‚úÖ Hourly snapshots saved: {results['saved_snapshots']}/{results['total_accounts']}")

        return {
            "success": True,
            "message": f"Saved {results['saved_snapshots']} snapshots for {results['total_accounts']} accounts across {results['total_projects']} projects",
            "timestamp": datetime.now().isoformat(),
            **results
        }

    except Exception as e:
        logger.error(f"‚ùå Hourly snapshots error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Hourly snapshots failed: {str(e)}")

@app.get("/api/list_all_projects")
async def list_all_projects():
    """–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –ø—Ä–æ–µ–∫—Ç—ã —Å ID (–±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏, –¥–ª—è –¥–µ–±–∞–≥–∞)"""
    projects = project_manager.get_all_projects()

    result = []
    for project in projects:
        result.append({
            "id": project['id'],
            "name": project['name'],
            "is_active": project.get('is_active', True),
            "is_finished": project.get('is_finished', False)
        })

    return {"success": True, "projects": result}

@app.post("/api/projects/{project_id}/generate_test_history")
async def generate_test_history(
    project_id: str,
    days: int = 14
):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ (–¥–ª—è –¥–µ–º–æ/—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)

    :param project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
    :param days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 14)
    """
    logger.info(f"üìä Generating test history for project {project_id} ({days} days)")

    if not project_sheets:
        raise HTTPException(status_code=503, detail="Google Sheets not available")

    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    try:
        import random

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets
        accounts_data = project_sheets.get_project_accounts(project['name'])

        results = {
            "project": project['name'],
            "days_generated": days,
            "accounts_processed": 0,
            "snapshots_created": 0
        }

        # –ü–æ–ª—É—á–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã –∏–∑ SQLite
        sqlite_accounts = project_manager.get_project_social_accounts(project_id)

        for account_data in accounts_data:
            profile_link = account_data.get('Link', '').strip()
            if not profile_link:
                continue

            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∞–∫–∫–∞—É–Ω—Ç –≤ SQLite
            matching_account = next((acc for acc in sqlite_accounts if acc['profile_link'] == profile_link), None)
            if not matching_account:
                continue

            results["accounts_processed"] += 1

            # –¢–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ Sheets
            current_followers = int(account_data.get('Followers', 0) or 0)
            current_likes = int(account_data.get('Likes', 0) or 0)
            current_videos = int(account_data.get('Videos', 0) or 0)
            current_views = int(account_data.get('Views', 0) or 0)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ—Ç (days) –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–æ —Å–µ–≥–æ–¥–Ω—è
            for day_offset in range(days, -1, -1):
                snapshot_date = datetime.now() - timedelta(days=day_offset)

                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ –¥–Ω—è (—Å–∏–º—É–ª—è—Ü–∏—è —Ä–æ—Å—Ç–∞)
                # –ß–µ–º –¥–∞–ª—å—à–µ –≤ –ø—Ä–æ—à–ª–æ–µ, —Ç–µ–º –º–µ–Ω—å—à–µ –∑–Ω–∞—á–µ–Ω–∏—è
                progress = 1 - (day_offset / days)  # 0 –≤ –Ω–∞—á–∞–ª–µ, 1 —Å–µ–≥–æ–¥–Ω—è

                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ (¬±10%)
                random_factor = 1 + random.uniform(-0.1, 0.1)

                day_followers = int(current_followers * progress * random_factor)
                day_likes = int(current_likes * progress * random_factor)
                day_videos = int(current_videos * progress * random_factor)
                day_views = int(current_views * progress * random_factor)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º snapshot
                success = project_manager.add_account_snapshot(
                    account_id=matching_account['id'],
                    followers=day_followers,
                    likes=day_likes,
                    comments=0,
                    videos=day_videos,
                    views=day_views
                )

                if success:
                    results["snapshots_created"] += 1
                    # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è snapshot –≤ –±–∞–∑–µ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –¥–∞—Ç—É
                    project_manager.db.cursor.execute('''
                        UPDATE account_snapshots
                        SET snapshot_time = ?
                        WHERE account_id = ? AND snapshot_time = (
                            SELECT MAX(snapshot_time) FROM account_snapshots WHERE account_id = ?
                        )
                    ''', (snapshot_date.isoformat(), matching_account['id'], matching_account['id']))
                    project_manager.db.conn.commit()

        logger.info(f"‚úÖ Test history generated: {results['snapshots_created']} snapshots for {results['accounts_processed']} accounts")

        return {
            "success": True,
            "message": f"Generated {results['snapshots_created']} test snapshots across {days} days for {results['accounts_processed']} accounts",
            **results
        }

    except Exception as e:
        logger.error(f"‚ùå Test history generation error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Test history generation failed: {str(e)}")

@app.get("/api/projects/{project_id}/debug_snapshots")
async def debug_project_snapshots(project_id: str):
    """Debug endpoint to check snapshots and dates for a project"""
    try:
        # Get project info
        project = project_manager.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")

        # Get accounts for this project
        project_manager.db.cursor.execute('''
            SELECT id, username, profile_link, platform
            FROM project_social_accounts
            WHERE project_id = ? AND is_active = 1
        ''', (project_id,))
        accounts = [{'id': row[0], 'username': row[1], 'link': row[2], 'platform': row[3]}
                   for row in project_manager.db.cursor.fetchall()]

        # Get snapshot date range for each account
        snapshot_info = []
        for account in accounts:
            project_manager.db.cursor.execute('''
                SELECT
                    MIN(DATE(snapshot_time)) as first_date,
                    MAX(DATE(snapshot_time)) as last_date,
                    COUNT(*) as snapshot_count
                FROM account_snapshots
                WHERE account_id = ?
            ''', (account['id'],))
            result = project_manager.db.cursor.fetchone()
            snapshot_info.append({
                'account': account['username'],
                'platform': account['platform'],
                'first_snapshot': result[0] if result else None,
                'last_snapshot': result[1] if result else None,
                'snapshot_count': result[2] if result else 0
            })

        return {
            "project": {
                "id": project['id'],
                "name": project['name'],
                "start_date": project.get('start_date'),
                "end_date": project.get('end_date'),
                "target_views": project.get('target_views', 0),
                "kpi_views": project.get('kpi_views', 1000)
            },
            "accounts": snapshot_info,
            "total_accounts": len(accounts)
        }

    except Exception as e:
        logger.error(f"‚ùå Debug endpoint error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/projects/{project_id}/fix_dates_for_test_data")
async def fix_project_dates_for_test_data(project_id: str):
    """Update project start_date to match the earliest snapshot (for test data)"""
    try:
        # Get project info
        project = project_manager.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")

        # Get accounts for this project
        project_manager.db.cursor.execute('''
            SELECT id FROM project_social_accounts
            WHERE project_id = ? AND is_active = 1
        ''', (project_id,))
        account_ids = [row[0] for row in project_manager.db.cursor.fetchall()]

        if not account_ids:
            raise HTTPException(status_code=400, detail="No accounts found for project")

        # Find the earliest snapshot date
        placeholders = ','.join('?' * len(account_ids))
        project_manager.db.cursor.execute(f'''
            SELECT MIN(DATE(snapshot_time)) as earliest_date
            FROM account_snapshots
            WHERE account_id IN ({placeholders})
        ''', account_ids)
        result = project_manager.db.cursor.fetchone()
        earliest_date = result[0] if result and result[0] else None

        if not earliest_date:
            raise HTTPException(status_code=400, detail="No snapshots found for project")

        # Update project start_date
        old_start_date = project.get('start_date')
        project_manager.db.cursor.execute('''
            UPDATE projects
            SET start_date = ?
            WHERE id = ?
        ''', (earliest_date, project_id))
        project_manager.db.conn.commit()

        return {
            "success": True,
            "message": f"Updated project start_date from {old_start_date} to {earliest_date}",
            "old_start_date": old_start_date,
            "new_start_date": earliest_date
        }

    except Exception as e:
        logger.error(f"‚ùå Fix dates error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/projects/{project_id}/update_target_views")
async def update_project_target_views(project_id: str, target_views: int):
    """Update project target_views"""
    try:
        # Get project info
        project = project_manager.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")

        # Update target_views
        old_target = project.get('target_views', 0)
        project_manager.db.cursor.execute('''
            UPDATE projects
            SET target_views = ?
            WHERE id = ?
        ''', (target_views, project_id))
        project_manager.db.conn.commit()

        return {
            "success": True,
            "message": f"Updated target_views from {old_target} to {target_views}",
            "old_target_views": old_target,
            "new_target_views": target_views
        }

    except Exception as e:
        logger.error(f"‚ùå Update target_views error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/projects/{project_id}/clear_snapshots")
async def clear_project_snapshots(project_id: str, keep_last_n: int = 0):
    """Clear snapshots for a project, optionally keeping last N snapshots per account"""
    try:
        # Get project info
        project = project_manager.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")

        # Get accounts for this project
        project_manager.db.cursor.execute('''
            SELECT id FROM project_social_accounts
            WHERE project_id = ? AND is_active = 1
        ''', (project_id,))
        account_ids = [row[0] for row in project_manager.db.cursor.fetchall()]

        if not account_ids:
            raise HTTPException(status_code=400, detail="No accounts found for project")

        total_deleted = 0

        if keep_last_n == 0:
            # Delete all snapshots for these accounts
            placeholders = ','.join('?' * len(account_ids))
            project_manager.db.cursor.execute(f'''
                DELETE FROM account_snapshots
                WHERE account_id IN ({placeholders})
            ''', account_ids)
            total_deleted = project_manager.db.cursor.rowcount
        else:
            # Keep last N snapshots per account
            for account_id in account_ids:
                # Get IDs to keep
                project_manager.db.cursor.execute(f'''
                    SELECT id FROM account_snapshots
                    WHERE account_id = ?
                    ORDER BY snapshot_time DESC
                    LIMIT {keep_last_n}
                ''', (account_id,))
                keep_ids = [row[0] for row in project_manager.db.cursor.fetchall()]

                if keep_ids:
                    keep_placeholders = ','.join('?' * len(keep_ids))
                    project_manager.db.cursor.execute(f'''
                        DELETE FROM account_snapshots
                        WHERE account_id = ? AND id NOT IN ({keep_placeholders})
                    ''', [account_id] + keep_ids)
                else:
                    # No snapshots to keep, delete all
                    project_manager.db.cursor.execute('''
                        DELETE FROM account_snapshots
                        WHERE account_id = ?
                    ''', (account_id,))

                total_deleted += project_manager.db.cursor.rowcount

        project_manager.db.conn.commit()

        return {
            "success": True,
            "message": f"Deleted {total_deleted} snapshots for project {project['name']}",
            "project_id": project_id,
            "project_name": project['name'],
            "snapshots_deleted": total_deleted,
            "kept_per_account": keep_last_n
        }

    except Exception as e:
        logger.error(f"‚ùå Clear snapshots error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/projects/{project_id}")
async def delete_project(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """–ü–æ–ª–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤)"""
    user_id = str(user.get('id'))

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    if user_id not in [str(admin_id) for admin_id in ADMIN_IDS]:
        raise HTTPException(status_code=403, detail="Admin access required")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–æ–µ–∫—Ç
    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    # STEP 1: –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –ª–∏—Å—Ç –∏–∑ Google Sheets –ü–ï–†–ï–î —É–¥–∞–ª–µ–Ω–∏–µ–º –∏–∑ –ë–î
    # (—á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å orphan sheets –µ—Å–ª–∏ –ë–î —É–¥–∞–ª–µ–Ω–∞, –Ω–æ sheet –æ—Å—Ç–∞–ª—Å—è)
    sheet_deletion_failed = False
    if project_sheets:
        try:
            logger.info(f"üîÑ Attempting to delete Google Sheet for project '{project['name']}'...")
            project_sheets.delete_project_sheet(project['name'])
            logger.info(f"‚úÖ Google Sheet '{project['name']}' deleted successfully")
        except Exception as e:
            sheet_deletion_failed = True
            logger.error(
                f"{'='*80}\n"
                f"‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL WARNING ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n"
                f"Failed to delete Google Sheet '{project['name']}' after retries!\n"
                f"Error: {e}\n"
                f"The project will still be deleted from the database to prevent phantom projects.\n"
                f"MANUAL ACTION REQUIRED: Delete the orphan Google Sheet '{project['name']}' manually!\n"
                f"{'='*80}"
            )
            # Continue with DB deletion despite sheet deletion failure

    # STEP 2: –£–¥–∞–ª—è–µ–º –ø—Ä–æ–µ–∫—Ç –∏–∑ –ë–î (–¥–∞–∂–µ –µ—Å–ª–∏ Google Sheet –Ω–µ —É–¥–∞–ª–∏–ª—Å—è)
    success = project_manager.delete_project_fully(project_id)

    if not success:
        raise HTTPException(status_code=500, detail="Failed to delete project from database")

    # Log final status
    if sheet_deletion_failed:
        logger.warning(
            f"‚ö†Ô∏è Project {project_id} deleted from DB by admin {user_id}, "
            f"but Google Sheet '{project['name']}' may still exist!"
        )
    else:
        logger.info(f"‚úÖ Project {project_id} fully deleted (DB + Sheet) by admin {user_id}")

    return {"success": True, "message": "Project deleted successfully"}

@app.post("/api/projects/{project_id}/finish")
async def finish_project(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤)"""
    user_id = str(user.get('id'))

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    if user_id not in [str(admin_id) for admin_id in ADMIN_IDS]:
        raise HTTPException(status_code=403, detail="Admin access required")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–æ–µ–∫—Ç
    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ–µ–∫—Ç (is_active = 0)
    success = project_manager.finish_project(project_id)

    if not success:
        raise HTTPException(status_code=500, detail="Failed to finish project")

    logger.info(f"‚úÖ Project {project_id} finished by admin {user_id}")
    return {"success": True, "message": "Project finished successfully"}

@app.get("/api/accounts/{account_id}")
async def get_social_account(
    account_id: str,
    user: dict = Depends(get_current_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞"""
    account = project_manager.get_social_account(account_id)
    if not account:
        raise HTTPException(status_code=404, detail="Account not found")
    return {"success": True, "account": account}

@app.put("/api/accounts/{account_id}")
async def update_social_account(
    account_id: str,
    updates: SocialAccountUpdate,
    user: dict = Depends(get_current_user)
):
    """–û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞"""
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç–∞
    account = project_manager.get_social_account(account_id)
    if not account:
        raise HTTPException(status_code=404, detail="Account not found")

    # –û–±–Ω–æ–≤–ª—è–µ–º –≤ –ë–î
    update_data = {k: v for k, v in updates.dict().items() if v is not None}
    success = project_manager.update_social_account(account_id, **update_data)

    if not success:
        raise HTTPException(status_code=400, detail="Failed to update account")

    return {"success": True, "message": "Account updated successfully"}

@app.delete("/api/accounts/{account_id}")
async def delete_social_account(
    account_id: str,
    user: dict = Depends(get_current_user)
):
    """–£–¥–∞–ª–∏—Ç—å —Å–æ—Ü–∏–∞–ª—å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞"""
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç–∞ –∏ –ø—Ä–æ–µ–∫—Ç–∞
    account = project_manager.get_social_account(account_id)
    if not account:
        raise HTTPException(status_code=404, detail="Account not found")

    project = project_manager.get_project(account['project_id'])

    # –£–¥–∞–ª—è–µ–º –∏–∑ –ë–î
    success = project_manager.remove_social_account_from_project(account_id)
    if not success:
        raise HTTPException(status_code=400, detail="Failed to delete account")

    # –£–¥–∞–ª—è–µ–º –∏–∑ Google Sheets (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if project_sheets and project:
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º profile_link –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ Link
            project_sheets.remove_account_from_sheet(project['name'], account['profile_link'])
            logger.info(f"‚úÖ –ê–∫–∫–∞—É–Ω—Ç {account['profile_link']} —É–¥–∞–ª–µ–Ω –∏–∑ Google Sheets")
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ Google Sheets: {e}")

    return {"success": True, "message": "Account deleted successfully"}

@app.post("/api/accounts/{account_id}/snapshot")
async def add_account_snapshot(
    account_id: str,
    snapshot: AccountSnapshot,
    user: dict = Depends(get_current_user)
):
    """–î–æ–±–∞–≤–∏—Ç—å —Å–Ω–∏–º–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–∫–∫–∞—É–Ω—Ç–∞"""
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç–∞
    account = project_manager.get_social_account(account_id)
    if not account:
        raise HTTPException(status_code=404, detail="Account not found")

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–Ω–∏–º–æ–∫ –≤ –ë–î
    success = project_manager.add_account_snapshot(
        account_id=account_id,
        followers=snapshot.followers,
        likes=snapshot.likes,
        comments=snapshot.comments,
        videos=snapshot.videos,
        views=snapshot.views
    )

    if not success:
        raise HTTPException(status_code=400, detail="Failed to add snapshot")

    # –û–±–Ω–æ–≤–ª—è–µ–º –≤ Google Sheets (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if project_sheets:
        try:
            project = project_manager.get_project(account['project_id'])
            if project:
                project_sheets.update_account_stats(
                    project['name'],
                    account['username'],
                    snapshot.dict()
                )
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Google Sheets: {e}")

    return {"success": True, "message": "Snapshot added successfully"}

@app.get("/api/accounts/{account_id}/snapshots")
async def get_account_snapshots(
    account_id: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    limit: int = 100,
    user: dict = Depends(get_current_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–Ω–∏–º–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–∫–∫–∞—É–Ω—Ç–∞"""
    snapshots = project_manager.get_account_snapshots(
        account_id, start_date, end_date, limit
    )
    return {"success": True, "snapshots": snapshots}

@app.get("/api/accounts/{account_id}/daily-stats")
async def get_account_daily_stats(
    account_id: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    user: dict = Depends(get_current_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–∫–∫–∞—É–Ω—Ç–∞ —Å –ø—Ä–∏—Ä–æ—Å—Ç–æ–º"""
    stats = project_manager.get_account_daily_stats(
        account_id, start_date, end_date
    )
    return {"success": True, "stats": stats}

@app.post("/api/projects/{project_id}/import_from_sheets")
async def import_from_sheets(
    project_id: str,
    user: dict = Depends(get_current_user)
):
    """–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets –≤ –ë–î (Reverse Sync)"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø –∫ –ø—Ä–æ–µ–∫—Ç—É
    user_id = str(user.get('id'))
    user_projects = project_manager.get_user_projects(user_id)
    if not any(p['id'] == project_id for p in user_projects):
        raise HTTPException(status_code=403, detail="Access denied")

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–µ–∫—Ç
    project = project_manager.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    if not project_sheets:
        raise HTTPException(status_code=503, detail="Google Sheets integration not available")

    try:
        # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheet
        sheet_data = project_sheets.read_project_sheet(project['name'])

        if not sheet_data:
            return {
                "success": True,
                "message": "No data found in Google Sheet",
                "imported_count": 0,
                "updated_count": 0
            }

        imported_count = 0
        updated_count = 0

        for row in sheet_data:
            try:
                username = row.get('@Username', '').strip()
                link = row.get('Link', '').strip()

                if not username and not link:
                    continue

                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞–∫–∫–∞—É–Ω—Ç –≤ –ë–î –ø–æ username –∏–ª–∏ link
                accounts = project_manager.get_project_social_accounts(project_id)
                matching_account = None

                for acc in accounts:
                    if (username and acc.get('username') == username) or \
                       (link and acc.get('profile_link') == link):
                        matching_account = acc
                        break

                if matching_account:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞–∫–∫–∞—É–Ω—Ç —á–µ—Ä–µ–∑ snapshot
                    followers = int(row.get('Followers', 0) or 0)
                    likes = int(row.get('Likes', 0) or 0)
                    comments = int(row.get('Comments', 0) or 0)
                    videos = int(row.get('Videos', 0) or 0)
                    views = int(row.get('Views', 0) or 0)

                    # –î–æ–±–∞–≤–ª—è–µ–º snapshot
                    success = project_manager.add_account_snapshot(
                        account_id=matching_account['id'],
                        followers=followers,
                        likes=likes,
                        comments=comments,
                        videos=videos,
                        views=views
                    )

                    if success:
                        updated_count += 1
                        logger.info(f"Updated account {username or link} from Sheets")
                else:
                    # –ê–∫–∫–∞—É–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω - –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                    logger.warning(f"Account {username or link} not found in DB, skipping")

            except Exception as e:
                logger.error(f"Error importing row: {e}")
                continue

        return {
            "success": True,
            "message": f"Import completed: {updated_count} accounts updated",
            "imported_count": imported_count,
            "updated_count": updated_count
        }

    except Exception as e:
        logger.error(f"Error importing from sheets: {e}")
        raise HTTPException(status_code=500, detail=f"Import failed: {str(e)}")

@app.post("/api/admin/force_migration")
async def force_database_migration():
    """
    Force database migration to add missing columns (ADMIN ONLY)

    This endpoint manually adds the total_videos_fetched column to account_snapshots
    if it's missing. Useful for fixing production databases.
    """
    try:
        logger.info("üîß [ADMIN] Force migration requested")

        # Check if table exists
        db.cursor.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name='account_snapshots'"
        )

        if not db.cursor.fetchone():
            return {
                "success": False,
                "message": "Table account_snapshots does not exist"
            }

        # Check current columns
        db.cursor.execute("PRAGMA table_info(account_snapshots)")
        columns = [column[1] for column in db.cursor.fetchall()]
        logger.info(f"üîç Current columns in account_snapshots: {columns}")

        # Check if migration needed
        if 'total_videos_fetched' in columns:
            return {
                "success": True,
                "message": "Column total_videos_fetched already exists",
                "columns": columns
            }

        # Add the column
        logger.info("‚ûï Adding column total_videos_fetched to account_snapshots...")
        db.cursor.execute('ALTER TABLE account_snapshots ADD COLUMN total_videos_fetched INTEGER DEFAULT 0')
        db.conn.commit()
        logger.info("‚úÖ Column total_videos_fetched added successfully")

        # Verify
        db.cursor.execute("PRAGMA table_info(account_snapshots)")
        new_columns = [column[1] for column in db.cursor.fetchall()]

        return {
            "success": True,
            "message": "Migration completed successfully",
            "columns_before": columns,
            "columns_after": new_columns
        }

    except Exception as e:
        logger.error(f"‚ùå Force migration failed: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Migration failed: {str(e)}")


@app.post("/api/admin/smart_sync")
async def trigger_smart_sync(project_id: Optional[str] = None):
    """
    Trigger smart sync manually or via cron job

    This endpoint can be called:
    - Manually for testing
    - By Render Cron Jobs (free tier alternative to Celery Beat)
    - By any external scheduler

    Query params:
        project_id (optional): Sync specific project, or all projects if not provided

    Returns:
        Sync results with statistics
    """
    try:
        logger.info(f"üîÑ [ADMIN] Smart sync triggered via HTTP (project_id={project_id})")

        from config import DEFAULT_GOOGLE_SHEETS_NAME, GOOGLE_SHEETS_CREDENTIALS_JSON
        from smart_sync import sync_all_projects_standalone, sync_single_project_standalone

        if project_id:
            # Sync single project
            result = sync_single_project_standalone(
                db=db,
                sheets_credentials=GOOGLE_SHEETS_CREDENTIALS_JSON,
                sheets_name=DEFAULT_GOOGLE_SHEETS_NAME,
                project_id=project_id
            )
            logger.info(f"‚úÖ [ADMIN] Smart sync completed for project {project_id}")
        else:
            # Sync all projects
            result = sync_all_projects_standalone(
                db=db,
                sheets_credentials=GOOGLE_SHEETS_CREDENTIALS_JSON,
                sheets_name=DEFAULT_GOOGLE_SHEETS_NAME
            )
            logger.info(f"‚úÖ [ADMIN] Smart sync completed for all projects")

        return result

    except Exception as e:
        logger.error(f"‚ùå Smart sync failed: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Smart sync failed: {str(e)}")


@app.get("/api/admin/sync_status")
async def get_sync_status():
    """
    Get sync status and statistics

    Returns information about:
    - Total projects
    - Active projects
    - Last sync time (if available)
    - Cache status

    Useful for monitoring and debugging
    """
    try:
        from project_manager import ProjectManager

        pm = ProjectManager(db)

        # Get project counts
        all_projects = pm.get_all_projects()
        active_projects = [p for p in all_projects if p.get('is_active', 1) == 1]

        # Check cache status
        from cache import cache

        return {
            "success": True,
            "total_projects": len(all_projects),
            "active_projects": len(active_projects),
            "cache_enabled": cache.enabled,
            "timestamp": datetime.utcnow().isoformat()
        }

    except Exception as e:
        logger.error(f"‚ùå Failed to get sync status: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get sync status: {str(e)}")


# ============ EMAIL FARM ENDPOINTS ============

@app.post("/api/admin/emails/upload")
async def admin_upload_email_account(
    data: EmailAccountUpload,
    x_telegram_init_data: str = Header(None)
):
    """
    [ADMIN ONLY] Upload single email account to farm

    Body:
    - email: Email address
    - password: Plain password (will be encrypted)
    - proxy: Optional proxy string (socks5://user:pass@ip:port)
    - project_id: Optional project ID
    """
    if not email_farm_db or not email_encryption:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate user
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    # Check admin
    if user_id not in ADMIN_IDS:
        raise HTTPException(status_code=403, detail="Admin access required")

    try:
        # Encrypt password
        encrypted_password = email_encryption.encrypt(data.password)

        # Save to database
        email_id = email_farm_db.add_email_account(
            email=data.email,
            password_encrypted=encrypted_password,
            proxy_string=data.proxy,
            project_id=data.project_id
        )

        if not email_id:
            raise HTTPException(status_code=400, detail="Email already exists")

        logger.info(f"‚úÖ [ADMIN {user_id}] Added email: {data.email}")

        return {
            "success": True,
            "email_id": email_id,
            "email": data.email,
            "status": "free"
        }

    except Exception as e:
        logger.error(f"‚ùå Failed to upload email: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/admin/emails/bulk_upload")
async def admin_bulk_upload_emails(
    data: EmailAccountBulkUpload,
    x_telegram_init_data: str = Header(None)
):
    """
    [ADMIN ONLY] Bulk upload email accounts

    Accepts text format:
    email:password:proxy
    or
    email:password

    Example:
    accounts: [
        {email: "test1@outlook.com", password: "pass123", proxy: "socks5://user:pass@ip:port"},
        {email: "test2@outlook.com", password: "pass456"}
    ]
    """
    if not email_farm_db or not email_encryption:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate user
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    # Check admin
    if user_id not in ADMIN_IDS:
        raise HTTPException(status_code=403, detail="Admin access required")

    results = {
        "success": 0,
        "failed": 0,
        "errors": []
    }

    for account in data.accounts:
        try:
            # Encrypt password (for password auth or as placeholder)
            encrypted_password = email_encryption.encrypt(account.password) if account.password else ""

            # Encrypt OAuth2 tokens if provided
            encrypted_refresh_token = None
            if account.refresh_token:
                encrypted_refresh_token = email_encryption.encrypt(account.refresh_token)

            # Save to database
            email_id = email_farm_db.add_email_account(
                email=account.email,
                password_encrypted=encrypted_password,
                proxy_string=account.proxy,
                project_id=account.project_id,
                refresh_token_encrypted=encrypted_refresh_token,
                client_id=account.client_id,
                auth_type=account.auth_type
            )

            if email_id:
                results["success"] += 1
                logger.info(f"‚úÖ [BULK] Added: {account.email} (auth_type: {account.auth_type})")

                # Log to Google Sheets (PostBD) - –Ω–æ–≤–∞—è –ø–æ—á—Ç–∞ –≤ —Å—Ç–∞—Ç—É—Å–µ free
                if email_sheets:
                    try:
                        email_sheets.log_new_email(
                            sheet_name="Post",
                            email=account.email,
                            has_proxy=bool(account.proxy)
                        )
                        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É API –≤—ã–∑–æ–≤–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limit
                        await asyncio.sleep(0.3)
                    except Exception as sheet_error:
                        logger.warning(f"‚ö†Ô∏è Failed to log bulk upload to PostBD: {sheet_error}")
            else:
                results["failed"] += 1
                results["errors"].append(f"{account.email}: Already exists")

        except Exception as e:
            results["failed"] += 1
            results["errors"].append(f"{account.email}: {str(e)}")
            logger.error(f"‚ùå Failed to add {account.email}: {e}")

    logger.info(f"‚úÖ [ADMIN {user_id}] Bulk upload: {results['success']} success, {results['failed']} failed")

    return results


@app.post("/api/admin/emails/set_limit")
async def admin_set_user_email_limit(
    data: SetUserEmailLimit,
    x_telegram_init_data: str = Header(None)
):
    """
    [ADMIN ONLY] Set user email access limit

    Body:
    - user_id: Telegram user ID
    - max_emails: Maximum active emails allowed
    - can_access: Whether user can access emails
    """
    if not email_farm_db:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate admin
    user_data = validate_telegram_init_data(x_telegram_init_data)
    admin_id = user_data['id']

    if admin_id not in ADMIN_IDS:
        raise HTTPException(status_code=403, detail="Admin access required")

    try:
        success = email_farm_db.set_user_limit(
            user_id=data.user_id,
            max_emails=data.max_emails,
            can_access=data.can_access
        )

        if not success:
            raise HTTPException(status_code=500, detail="Failed to set limit")

        logger.info(f"‚úÖ [ADMIN {admin_id}] Set limit for user {data.user_id}: {data.max_emails} emails")

        return {
            "success": True,
            "user_id": data.user_id,
            "max_emails": data.max_emails,
            "can_access": data.can_access
        }

    except Exception as e:
        logger.error(f"‚ùå Failed to set user limit: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/admin/emails/stats")
async def admin_get_email_stats(x_telegram_init_data: str = Header(None)):
    """
    [ADMIN ONLY] Get email farm statistics

    Returns:
    - total_emails
    - free
    - active
    - banned
    - archived
    - users_with_access
    """
    if not email_farm_db:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate admin
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    if user_id not in ADMIN_IDS:
        raise HTTPException(status_code=403, detail="Admin access required")

    try:
        stats = email_farm_db.get_stats()
        logger.info(f"üìä [ADMIN {user_id}] Requested email stats")
        return stats

    except Exception as e:
        logger.error(f"‚ùå Failed to get email stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/admin/emails/clear_all")
async def admin_clear_all_emails(x_telegram_init_data: str = Header(None)):
    """
    [ADMIN ONLY] Clear all emails from Email Farm database

    Deletes:
    - All email accounts
    - All email history records

    Returns:
    - deleted_emails: number of deleted email accounts
    - deleted_history: number of deleted history records
    """
    if not email_farm_db:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate admin
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    if user_id not in ADMIN_IDS:
        raise HTTPException(status_code=403, detail="Admin access required")

    try:
        cursor = email_farm_db.conn.cursor()

        # Delete all email history
        cursor.execute("DELETE FROM email_history")
        deleted_history = cursor.rowcount

        # Delete all email accounts
        cursor.execute("DELETE FROM email_accounts")
        deleted_emails = cursor.rowcount

        email_farm_db.conn.commit()

        logger.warning(f"üóëÔ∏è [ADMIN {user_id}] CLEARED ALL EMAIL FARM DATA: {deleted_emails} emails, {deleted_history} history records")

        return {
            "success": True,
            "deleted_emails": deleted_emails,
            "deleted_history": deleted_history
        }

    except Exception as e:
        logger.error(f"‚ùå Failed to clear emails: {e}")
        email_farm_db.conn.rollback()
        raise HTTPException(status_code=500, detail=str(e))


# ============ USER EMAIL FARM ENDPOINTS ============

@app.get("/api/emails/my_list")
async def get_my_emails(x_telegram_init_data: str = Header(None)):
    """
    Get list of emails assigned to current user

    Returns list of emails with:
    - id
    - email
    - status
    - assigned_at
    """
    if not email_farm_db:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate user
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    try:
        # Check user access
        limit_info = email_farm_db.get_user_limit(user_id)
        if not limit_info.get('can_access_emails'):
            raise HTTPException(status_code=403, detail="Email access disabled for this user")

        # Get user's emails
        emails = email_farm_db.get_user_emails(user_id)

        # Hide proxy info from response
        for email in emails:
            email.pop('proxy_string', None)

        logger.info(f"üìã User {user_id} has {len(emails)} emails")

        return {
            "success": True,
            "emails": emails,
            "limit": limit_info
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to get user emails: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/emails/allocate")
async def allocate_email_to_me(x_telegram_init_data: str = Header(None)):
    """
    Allocate free email to current user

    Checks user limits before allocation
    Returns allocated email info (without password)
    """
    if not email_farm_db:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate user
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    try:
        # Check if user is participant in at least one ACTIVE (not finished) project
        user_projects = project_manager.get_user_projects(str(user_id))
        has_active_project = any(
            project.get('is_active') and not project.get('is_finished')
            for project in user_projects
        )

        if not has_active_project:
            logger.warning(f"‚ö†Ô∏è User {user_id} tried to allocate email but has no active projects")
            raise HTTPException(
                status_code=403,
                detail="–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—Ä–æ—Å–∏—Ç—å –ø–æ—á—Ç—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–≤–ª—è–µ—Ç–µ—Å—å —É—á–∞—Å—Ç–Ω–∏–∫–æ–º –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"
            )

        # Check user access
        limit_info = email_farm_db.get_user_limit(user_id)
        if not limit_info.get('can_access_emails'):
            raise HTTPException(status_code=403, detail="Email access disabled")

        # Check if user reached limit
        active_count = email_farm_db.get_user_active_count(user_id)
        max_allowed = limit_info.get('max_active_emails', 5)

        if active_count >= max_allowed:
            raise HTTPException(
                status_code=400,
                detail=f"Email limit reached ({active_count}/{max_allowed})"
            )

        # Get free email
        free_email = email_farm_db.get_free_email()
        if not free_email:
            raise HTTPException(status_code=404, detail="No free emails available")

        # Allocate to user
        success = email_farm_db.allocate_email_to_user(free_email['id'], user_id)
        if not success:
            raise HTTPException(status_code=500, detail="Failed to allocate email")

        logger.info(f"‚úÖ User {user_id} allocated email: {free_email['email']}")

        # Log to Google Sheets (PostBD)
        if email_sheets:
            try:
                # –ü–æ–ª—É—á–∞–µ–º username –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                username = user_data.get('username', f"user_{user_id}")

                logger.info(f"üìä Logging allocation to PostBD: {free_email['email']} for user {username}")

                # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–¥–µ–ª–µ–Ω–∏–µ –ø–æ—á—Ç—ã (–ª–∏—Å—Ç = –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ MainBD –∏–ª–∏ Post)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º "Post" –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞
                email_sheets.log_email_allocation(
                    sheet_name="Post",
                    email=free_email['email'],
                    user_id=user_id,
                    username=username,
                    has_proxy=bool(free_email.get('proxy_string'))
                )
                logger.info(f"‚úÖ PostBD logging successful for {free_email['email']}")
            except Exception as sheet_error:
                logger.error(f"‚ùå Failed to log email allocation to PostBD: {sheet_error}")
                import traceback
                logger.error(traceback.format_exc())
        else:
            logger.warning("‚ö†Ô∏è Email Sheets Manager not initialized - skipping PostBD logging")

        # Return without password/proxy
        return {
            "success": True,
            "email_id": free_email['id'],
            "email": free_email['email'],
            "status": "active",
            "active_count": active_count + 1,
            "max_allowed": max_allowed
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to allocate email: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/emails/{email_id}/check_code")
async def check_email_for_code(
    email_id: int,
    x_telegram_init_data: str = Header(None)
):
    """
    Check latest email and extract verification code

    Connects to Outlook via IMAP (through proxy)
    Runs smart filter for security
    Returns extracted code if safe
    """
    if not email_farm_db or not email_encryption or not email_filter:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate user
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    try:
        # Get email account
        email_account = email_farm_db.get_email_by_id(email_id)
        if not email_account:
            raise HTTPException(status_code=404, detail="Email not found")

        # Verify ownership
        if email_account['assigned_user_id'] != user_id:
            raise HTTPException(status_code=403, detail="Email not assigned to you")

        # Check status
        if email_account['status'] != 'active':
            raise HTTPException(status_code=400, detail=f"Email status: {email_account['status']}")

        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π IMAP –∫–ª–∏–µ–Ω—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç auth_type
        auth_type = email_account.get('auth_type', 'password')

        if auth_type == 'oauth2':
            # OAuth2 –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
            if not email_account.get('refresh_token_encrypted') or not email_account.get('client_id'):
                raise HTTPException(status_code=400, detail="OAuth2 credentials missing")

            # –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ–º refresh token
            refresh_token = email_encryption.decrypt(email_account['refresh_token_encrypted'])

            # –°–æ–∑–¥–∞–µ–º OAuth2 IMAP –∫–ª–∏–µ–Ω—Ç
            imap_client = OutlookOAuth2IMAPClient(
                email=email_account['email'],
                refresh_token=refresh_token,
                client_id=email_account['client_id'],
                proxy_string=email_account.get('proxy_string')
            )
        else:
            # –û–±—ã—á–Ω–∞—è password –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
            plain_password = email_encryption.decrypt(email_account['password_encrypted'])

            imap_client = OutlookIMAPClient(
                email=email_account['email'],
                password=plain_password,
                proxy_string=email_account.get('proxy_string')
            )

        # Fetch latest emails
        # –î–ª—è OAuth2: –∏—Å–ø–æ–ª—å–∑—É–µ–º Outlook REST API (—Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ —Å –ø—Ä–æ–∫—Å–∏)
        # –î–ª—è password: –∏—Å–ø–æ–ª—å–∑—É–µ–º IMAP
        if email_account['auth_type'] == 'oauth2':
            logger.info(f"üì® –ò—Å–ø–æ–ª—å–∑—É–µ–º Outlook REST API v2.0 –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∏—Å–µ–º (OAuth2)")
            emails = await imap_client.get_latest_emails_graph_api(limit=5)
        else:
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ IMAP –¥–ª—è password auth
            logger.info(f"üì® –ò—Å–ø–æ–ª—å–∑—É–µ–º IMAP –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∏—Å–µ–º (password)")
            connected = await imap_client.connect()
            if not connected:
                raise HTTPException(status_code=500, detail="Failed to connect to email")

            emails = await imap_client.get_latest_emails(limit=5)
            await imap_client.disconnect()

        if not emails:
            # Log to Google Sheets (PostBD) - no emails
            if email_sheets:
                try:
                    email_sheets.log_email_check(
                        sheet_name="Post",
                        email=email_account['email'],
                        found_code=False,
                        is_safe=True,
                        subject="üì≠ No new emails"
                    )
                except Exception as sheet_error:
                    logger.warning(f"‚ö†Ô∏è Failed to log 'no emails' to PostBD: {sheet_error}")

            return {
                "success": True,
                "found_emails": False,
                "message": "No new emails"
            }

        # Analyze latest email
        latest = emails[0]
        analysis = email_filter.analyze_email(latest['subject'], latest['body'])

        # Log action
        email_farm_db.log_action(
            user_id=user_id,
            email_id=email_id,
            action='checked_code',
            details=f"Subject: {latest['subject']}"
        )

        # If unsafe, send security alert
        if not analysis['is_safe']:
            await send_security_alert(
                user_id=user_id,
                email=email_account['email'],
                subject=latest['subject'],
                reason=analysis['unsafe_reason']
            )

            logger.warning(f"‚ö†Ô∏è User {user_id} - Unsafe email detected: {analysis['unsafe_reason']}")

            # Log unsafe email to Google Sheets (PostBD)
            if email_sheets:
                try:
                    email_sheets.log_email_check(
                        sheet_name="Post",
                        email=email_account['email'],
                        found_code=False,
                        is_safe=False,
                        subject=f"‚ö†Ô∏è {latest['subject']} - {analysis['unsafe_reason']}"
                    )
                except Exception as sheet_error:
                    logger.warning(f"‚ö†Ô∏è Failed to log unsafe email to PostBD: {sheet_error}")

            return {
                "success": False,
                "is_safe": False,
                "reason": analysis['unsafe_reason'],
                "subject": latest['subject']
            }

        # Return safe result with code
        logger.info(f"‚úÖ User {user_id} - Code check safe: {email_account['email']}")

        # Log to Google Sheets (PostBD)
        if email_sheets:
            try:
                email_sheets.log_email_check(
                    sheet_name="Post",
                    email=email_account['email'],
                    found_code=bool(analysis['verification_code']),
                    is_safe=analysis['is_safe'],
                    subject=latest['subject'],
                    code=analysis['verification_code'] or ""
                )
            except Exception as sheet_error:
                logger.warning(f"‚ö†Ô∏è Failed to log email check to PostBD: {sheet_error}")

        return {
            "success": True,
            "is_safe": True,
            "verification_code": analysis['verification_code'],
            "all_codes": analysis['all_codes'],
            "subject": latest['subject'],
            "from": latest['from'],
            "date": latest['date']
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to check email code: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/emails/{email_id}/mark_banned")
async def mark_email_as_banned(
    email_id: int,
    x_telegram_init_data: str = Header(None)
):
    """
    Mark email as banned (user reported it as invalid/blocked)
    """
    if not email_farm_db:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate user
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    try:
        # Get email account
        email_account = email_farm_db.get_email_by_id(email_id)
        if not email_account:
            raise HTTPException(status_code=404, detail="Email not found")

        # Verify ownership
        if email_account['assigned_user_id'] != user_id:
            raise HTTPException(status_code=403, detail="Email not assigned to you")

        # Mark as banned
        success = email_farm_db.mark_email_banned(
            email_id=email_id,
            user_id=user_id,
            reason="User reported as banned/invalid"
        )

        if not success:
            raise HTTPException(status_code=500, detail="Failed to mark as banned")

        logger.info(f"‚úÖ User {user_id} marked email {email_id} as banned")

        # Log to Google Sheets (PostBD)
        if email_sheets:
            try:
                email_sheets.log_email_ban(
                    sheet_name="Post",
                    email=email_account['email'],
                    ban_reason="User reported as banned/invalid"
                )
            except Exception as sheet_error:
                logger.warning(f"‚ö†Ô∏è Failed to log email ban to PostBD: {sheet_error}")

        return {
            "success": True,
            "email_id": email_id,
            "status": "banned"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to mark email as banned: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/emails/{email_id}/complete")
async def complete_email_registration(
    email_id: int,
    x_telegram_init_data: str = Header(None)
):
    """
    Mark email registration as completed (move from Registration to My Emails)
    """
    if not email_farm_db:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate user
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    try:
        # Get email account
        email_account = email_farm_db.get_email_by_id(email_id)
        if not email_account:
            raise HTTPException(status_code=404, detail="Email not found")

        # Verify ownership
        if email_account['assigned_user_id'] != user_id:
            raise HTTPException(status_code=403, detail="Email not assigned to you")

        # Mark as completed
        success = email_farm_db.mark_email_completed(email_id)

        if not success:
            raise HTTPException(status_code=500, detail="Failed to complete registration")

        # Update Google Sheets
        if email_sheets:
            try:
                email_sheets.update_email_completed_status(
                    sheet_name="Post",
                    email=email_account['email'],
                    is_completed=True
                )
            except Exception as sheet_error:
                logger.warning(f"‚ö†Ô∏è Failed to update completed status in PostBD: {sheet_error}")

        logger.info(f"‚úÖ User {user_id} completed registration for email {email_id}")

        return {
            "success": True,
            "email_id": email_id,
            "is_completed": True
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to complete email registration: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/emails/{email_id}/reopen")
async def reopen_email_registration(
    email_id: int,
    x_telegram_init_data: str = Header(None)
):
    """
    Reopen email registration (move from My Emails back to Registration)
    """
    if not email_farm_db:
        raise HTTPException(status_code=503, detail="Email Farm not initialized")

    # Validate user
    user_data = validate_telegram_init_data(x_telegram_init_data)
    user_id = user_data['id']

    try:
        # Get email account
        email_account = email_farm_db.get_email_by_id(email_id)
        if not email_account:
            raise HTTPException(status_code=404, detail="Email not found")

        # Verify ownership
        if email_account['assigned_user_id'] != user_id:
            raise HTTPException(status_code=403, detail="Email not assigned to you")

        # Reopen registration
        success = email_farm_db.reopen_email_registration(email_id)

        if not success:
            raise HTTPException(status_code=500, detail="Failed to reopen registration")

        # Update Google Sheets
        if email_sheets:
            try:
                email_sheets.update_email_completed_status(
                    sheet_name="Post",
                    email=email_account['email'],
                    is_completed=False
                )
            except Exception as sheet_error:
                logger.warning(f"‚ö†Ô∏è Failed to update completed status in PostBD: {sheet_error}")

        logger.info(f"‚úÖ User {user_id} reopened email {email_id} for additional code")

        return {
            "success": True,
            "email_id": email_id,
            "is_completed": False
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to reopen email registration: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
