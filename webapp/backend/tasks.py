"""
Celery Tasks for View Counter WebApp

Background tasks for heavy operations:
- Google Sheets synchronization
- Periodic data sync
- Stats update notifications
"""

import os
import logging
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Try to import Celery, graceful fallback if not available
try:
    from celery import Celery
    CELERY_AVAILABLE = True
except ImportError:
    CELERY_AVAILABLE = False
    Celery = None
    logger.warning("‚ö†Ô∏è Celery not installed, background tasks disabled")

# Initialize Celery (only if available)
if CELERY_AVAILABLE:
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ REDIS_URL (Render) –∏–ª–∏ REDIS_HOST/PORT/PASSWORD (–ª–æ–∫–∞–ª—å–Ω–æ)
    redis_url = os.getenv('REDIS_URL')

    if redis_url:
        # Render –∏—Å–ø–æ–ª—å–∑—É–µ—Ç REDIS_URL
        # –û—á–∏—â–∞–µ–º –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫
        redis_url = redis_url.strip().strip('"').strip("'")

        # –î–æ–±–∞–≤–ª—è–µ–º /0 –µ—Å–ª–∏ URL –Ω–µ –∏–º–µ–µ—Ç –Ω–æ–º–µ—Ä–∞ DB
        if not redis_url.rstrip('/').split('/')[-1].isdigit():
            # URL –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ :6379 –∏–ª–∏ :6379/ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º /0
            broker_url = redis_url.rstrip('/') + '/0'
        else:
            broker_url = redis_url

        # Upstash –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¢–û–õ–¨–ö–û DB 0, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë –¥–ª—è broker –∏ result backend
        result_backend = broker_url

        logger.info(f"üì° Using REDIS_URL from environment")
        logger.info(f"üì° Broker URL: {broker_url[:50]}...")  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤
        logger.info(f"üì° Result Backend: {result_backend[:50]}...")  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º result backend —Ç–æ–∂–µ
    else:
        # –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞: REDIS_HOST/PORT/PASSWORD
        redis_host = os.getenv('REDIS_HOST', 'localhost')
        redis_port = os.getenv('REDIS_PORT', '6379')
        redis_password = os.getenv('REDIS_PASSWORD', '')

        if redis_password:
            broker_url = f'redis://:{redis_password}@{redis_host}:{redis_port}/1'
        else:
            broker_url = f'redis://{redis_host}:{redis_port}/1'

        result_backend = broker_url.replace('/1', '/2')
        logger.info(f"üì° Using REDIS_HOST={redis_host}:{redis_port}")

    celery_app = Celery(
        'view_counter_tasks',
        broker=broker_url,
        backend=result_backend
    )

    # SSL Configuration –¥–ª—è rediss://
    import ssl
    ssl_config = {}
    if broker_url.startswith('rediss://'):
        ssl_config = {
            'broker_use_ssl': {
                'ssl_cert_reqs': ssl.CERT_NONE
            },
            'redis_backend_use_ssl': {
                'ssl_cert_reqs': ssl.CERT_NONE
            }
        }

    # Celery Configuration
    celery_app.conf.update(
        task_serializer='json',
        accept_content=['json'],
        result_serializer='json',
        timezone='UTC',
        enable_utc=True,
        task_track_started=True,
        task_time_limit=600,  # 10 minutes max per task
        worker_prefetch_multiplier=1,  # Take one task at a time
        worker_max_tasks_per_child=50,  # Restart worker after 50 tasks (prevent memory leaks)
        **ssl_config  # –î–æ–±–∞–≤–ª—è–µ–º SSL –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    )
else:
    # Dummy celery_app for imports
    celery_app = None
    logger.warning("‚ö†Ô∏è Celery app not initialized (module not available)")


def _create_task_decorator():
    """Create task decorator or no-op if Celery unavailable"""
    if CELERY_AVAILABLE and celery_app:
        return celery_app.task
    else:
        # No-op decorator
        def dummy_decorator(*args, **kwargs):
            def wrapper(func):
                return func
            return wrapper
        return dummy_decorator

task = _create_task_decorator()

@task(name='sync_project_to_sheets')
def sync_project_to_sheets(project_id: str, project_name: str, accounts_data: list):
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ —Å Google Sheets (—Ñ–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞)

    Args:
        project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
        project_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
        accounts_data: –°–ø–∏—Å–æ–∫ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏

    Returns:
        dict: {"success": bool, "message": str, "synced_count": int}
    """
    logger.info(f"üì§ [Celery] Starting sync to Google Sheets for project {project_id}")

    try:
        # Import –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å circular imports
        from project_sheets_manager import ProjectSheetsManager
        from config import DEFAULT_GOOGLE_SHEETS_NAME, GOOGLE_SHEETS_CREDENTIALS_JSON

        # –°–æ–∑–¥–∞—ë–º –º–µ–Ω–µ–¥–∂–µ—Ä Google Sheets
        sheets_manager = ProjectSheetsManager(
            credentials_file="",
            spreadsheet_name=DEFAULT_GOOGLE_SHEETS_NAME,
            credentials_json=GOOGLE_SHEETS_CREDENTIALS_JSON
        )

        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –∞–∫–∫–∞—É–Ω—Ç
        synced_count = 0
        for account in accounts_data:
            try:
                # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–µ
                sheets_manager.update_account_in_project(
                    project_name=project_name,
                    account_url=account['profile_link'],
                    updates={
                        'Views': account.get('views', 0),
                        'Videos': account.get('videos', 0),
                        'Followers': account.get('followers', 0),
                        'Likes': account.get('likes', 0),
                        'Comments': account.get('comments', 0),
                    }
                )
                synced_count += 1
                logger.info(f"‚úÖ [Celery] Synced account {account.get('username', 'unknown')}")
            except Exception as e:
                logger.error(f"‚ùå [Celery] Failed to sync account {account.get('username')}: {e}")

        logger.info(f"‚úÖ [Celery] Sync completed: {synced_count}/{len(accounts_data)} accounts")

        return {
            "success": True,
            "message": f"Synced {synced_count} accounts to Google Sheets",
            "synced_count": synced_count
        }

    except Exception as e:
        logger.error(f"‚ùå [Celery] Sync to sheets failed: {e}")
        return {
            "success": False,
            "message": str(e),
            "synced_count": 0
        }


@task(name='sync_account_to_sheets')
def sync_account_to_sheets(project_name: str, account_data: dict):
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ —Å Google Sheets

    Args:
        project_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
        account_data: –î–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç–∞

    Returns:
        dict: {"success": bool, "message": str}
    """
    logger.info(f"üì§ [Celery] Syncing single account to Sheets: {account_data.get('username')}")

    try:
        from project_sheets_manager import ProjectSheetsManager
        from config import DEFAULT_GOOGLE_SHEETS_NAME, GOOGLE_SHEETS_CREDENTIALS_JSON

        sheets_manager = ProjectSheetsManager(
            credentials_file="",
            spreadsheet_name=DEFAULT_GOOGLE_SHEETS_NAME,
            credentials_json=GOOGLE_SHEETS_CREDENTIALS_JSON
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–∫–∫–∞—É–Ω—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ
        sheets_manager.update_account_in_project(
            project_name=project_name,
            account_url=account_data['profile_link'],
            updates={
                'Views': account_data.get('views', 0),
                'Videos': account_data.get('videos', 0),
                'Followers': account_data.get('followers', 0),
                'Likes': account_data.get('likes', 0),
                'Comments': account_data.get('comments', 0),
            }
        )

        logger.info(f"‚úÖ [Celery] Account synced: {account_data.get('username')}")

        return {
            "success": True,
            "message": f"Account {account_data.get('username')} synced"
        }

    except Exception as e:
        logger.error(f"‚ùå [Celery] Account sync failed: {e}")
        return {
            "success": False,
            "message": str(e)
        }


@task(name='periodic_sync_all_projects')
def periodic_sync_all_projects():
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é)

    Returns:
        dict: {"synced_projects": int, "failed_projects": int}
    """
    logger.info("üîÑ [Celery] Starting periodic sync for all active projects")

    try:
        from project_manager import ProjectManager
        from database_adapter import get_database

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–µ–∫—Ç–æ–≤
        db = get_database()
        project_manager = ProjectManager(db)

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
        all_projects = project_manager.get_all_projects()
        active_projects = [p for p in all_projects if p.get('is_active', 1) == 1]

        logger.info(f"üìä [Celery] Found {len(active_projects)} active projects")

        synced_count = 0
        failed_count = 0

        for project in active_projects:
            try:
                project_id = project['id']
                project_name = project['name']

                # –ü–æ–ª—É—á–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
                accounts = project_manager.get_project_social_accounts(project_id)

                if accounts:
                    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –≤ —Ñ–æ–Ω–µ
                    sync_project_to_sheets.delay(project_id, project_name, accounts)
                    synced_count += 1
                    logger.info(f"‚úÖ [Celery] Queued sync for project {project_name}")

            except Exception as e:
                logger.error(f"‚ùå [Celery] Failed to queue project {project.get('name')}: {e}")
                failed_count += 1

        logger.info(f"‚úÖ [Celery] Periodic sync completed: {synced_count} queued, {failed_count} failed")

        return {
            "synced_projects": synced_count,
            "failed_projects": failed_count
        }

    except Exception as e:
        logger.error(f"‚ùå [Celery] Periodic sync failed: {e}")
        return {
            "synced_projects": 0,
            "failed_projects": 0
        }


@task(name='smart_sync_all_projects')
def smart_sync_all_projects():
    """
    Smart sync for all active projects using MAX() merge strategy

    This is a Celery task wrapper around the standalone smart_sync function.
    It implements CQRS-lite architecture:
    1. Read from Google Sheets (manual edits)
    2. Parse fresh data (from parsers/SQLite)
    3. Merge using MAX() strategy
    4. Update SQLite
    5. Create daily snapshots

    Returns:
        dict: Sync results
    """
    logger.info("üîÑ [Celery] Starting smart sync for all projects")

    try:
        from database_adapter import get_database
        from config import DEFAULT_GOOGLE_SHEETS_NAME, GOOGLE_SHEETS_CREDENTIALS_JSON
        from smart_sync import sync_all_projects_standalone

        # Initialize database
        db = get_database()

        # Run smart sync
        result = sync_all_projects_standalone(
            db=db,
            sheets_credentials=GOOGLE_SHEETS_CREDENTIALS_JSON,
            sheets_name=DEFAULT_GOOGLE_SHEETS_NAME
        )

        logger.info(f"‚úÖ [Celery] Smart sync completed: {result.get('success_count', 0)} projects")

        return result

    except Exception as e:
        logger.error(f"‚ùå [Celery] Smart sync failed: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@task(name='smart_sync_single_project')
def smart_sync_single_project(project_id: str):
    """
    Smart sync for a single project

    Args:
        project_id: Project ID to sync

    Returns:
        dict: Sync results
    """
    logger.info(f"üîÑ [Celery] Starting smart sync for project {project_id}")

    try:
        from database_adapter import get_database
        from config import DEFAULT_GOOGLE_SHEETS_NAME, GOOGLE_SHEETS_CREDENTIALS_JSON
        from smart_sync import sync_single_project_standalone

        # Initialize database
        db = get_database()

        # Run smart sync
        result = sync_single_project_standalone(
            db=db,
            sheets_credentials=GOOGLE_SHEETS_CREDENTIALS_JSON,
            sheets_name=DEFAULT_GOOGLE_SHEETS_NAME,
            project_id=project_id
        )

        logger.info(f"‚úÖ [Celery] Smart sync completed for project {project_id}")

        return result

    except Exception as e:
        logger.error(f"‚ùå [Celery] Smart sync failed for project {project_id}: {e}")
        return {
            "success": False,
            "error": str(e),
            "project_id": project_id
        }


@task(name='refresh_project_stats')
def refresh_project_stats(job_id: str, project_id: str, platforms: dict,
                          date_from: str = None, date_to: str = None):
    """
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞ —á–µ—Ä–µ–∑ Celery —Å –±–∞—Ç—á–∏–Ω–≥–æ–º –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–æ–º

    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è 500-1000 –∞–∫–∫–∞—É–Ω—Ç–æ–≤:
    - –ë–∞—Ç—á–∏–Ω–≥ –ø–æ 50 –∞–∫–∫–∞—É–Ω—Ç–æ–≤
    - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π fetch —á–µ—Ä–µ–∑ ThreadPoolExecutor (15 –ø–æ—Ç–æ–∫–æ–≤)
    - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤ jobs —Ç–∞–±–ª–∏—Ü–µ
    - –ó–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limits

    Args:
        job_id: ID –∑–∞–¥–∞—á–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ jobs
        project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
        platforms: Dict –ø–ª–∞—Ç—Ñ–æ—Ä–º –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è {'tiktok': True, 'instagram': False, ...}
        date_from: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞ (YYYY-MM-DD)
        date_to: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∞ (YYYY-MM-DD)

    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    """
    import sys
    import os
    import time
    from concurrent.futures import ThreadPoolExecutor, as_completed

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ sys.path –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)

    from database_adapter import get_database
    from project_manager import ProjectManager
    from project_sheets_manager import ProjectSheetsManager
    from config import (
        DEFAULT_GOOGLE_SHEETS_NAME, GOOGLE_SHEETS_CREDENTIALS_JSON,
        RAPIDAPI_KEY, RAPIDAPI_HOST, RAPIDAPI_BASE_URL,
        INSTAGRAM_RAPIDAPI_KEY, INSTAGRAM_RAPIDAPI_HOST, INSTAGRAM_BASE_URL,
        FACEBOOK_RAPIDAPI_KEY, FACEBOOK_RAPIDAPI_HOST, FACEBOOK_APP_ID
    )

    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –±–∞—Ç—á–∏–Ω–≥–∞ –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
    BATCH_SIZE = 50  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 50 –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –∑–∞ —Ä–∞–∑
    MAX_WORKERS = 15  # –ú–∞–∫—Å–∏–º—É–º 15 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è RapidAPI)
    BATCH_DELAY = 2  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

    logger.info(f"üöÄ [Celery] Starting refresh_project_stats for job {job_id}")

    db = None
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        db = get_database()
        project_manager = ProjectManager(db)
        project = project_manager.get_project(project_id)

        if not project:
            db.update_job(job_id, status='failed', error='Project not found')
            return {'success': False, 'error': 'Project not found'}

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å job –Ω–∞ 'running'
        db.update_job(job_id, status='running')

        # –ü–æ–ª—É—á–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
        accounts = project_manager.get_project_social_accounts(project_id)
        total_accounts = len(accounts)

        # –§–∏–ª—å—Ç—Ä—É–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º –∏ —Å—Ç–∞—Ç—É—Å—É
        filtered_accounts = []
        for account in accounts:
            platform = account.get('platform', 'tiktok').lower()
            status = account.get('status', '').upper()

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞ –∏–ª–∏ —Å—Ç–∞—Ç—É—Å OLD
            if not platforms.get(platform, False):
                continue
            if status == 'OLD':
                continue

            filtered_accounts.append(account)

        total_to_process = len(filtered_accounts)
        logger.info(f"üìä Total accounts: {total_accounts}, to process: {total_to_process}")

        db.update_job(job_id, total=total_to_process, processed=0)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º API –∫–ª–∏–µ–Ω—Ç—ã (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)
        api_clients = {}

        def get_api_client(platform):
            """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API –∫–ª–∏–µ–Ω—Ç–æ–≤"""
            if platform not in api_clients:
                try:
                    if platform == 'tiktok':
                        from tiktok_api import TikTokAPI
                        api_clients['tiktok'] = TikTokAPI(
                            api_key=RAPIDAPI_KEY,
                            api_host=RAPIDAPI_HOST,
                            base_url=RAPIDAPI_BASE_URL
                        )
                    elif platform == 'instagram':
                        from instagram_api import InstagramAPI
                        api_clients['instagram'] = InstagramAPI(
                            api_key=INSTAGRAM_RAPIDAPI_KEY,
                            api_host=INSTAGRAM_RAPIDAPI_HOST,
                            base_url=INSTAGRAM_BASE_URL
                        )
                    elif platform == 'facebook':
                        from facebook_parser import FacebookAPI
                        api_clients['facebook'] = FacebookAPI(
                            api_key=FACEBOOK_RAPIDAPI_KEY,
                            api_host=FACEBOOK_RAPIDAPI_HOST,
                            app_id=FACEBOOK_APP_ID
                        )
                except Exception as e:
                    logger.error(f"‚ùå Failed to initialize {platform} API: {e}")
                    api_clients[platform] = None

            return api_clients.get(platform)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Google Sheets (–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
        try:
            sheets_manager = ProjectSheetsManager(
                credentials_file="",
                spreadsheet_name=DEFAULT_GOOGLE_SHEETS_NAME,
                credentials_json=GOOGLE_SHEETS_CREDENTIALS_JSON
            )
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Google Sheets: {e}")
            db.update_job(job_id, status='failed', error=f'Google Sheets init failed: {str(e)}')
            return {'success': False, 'error': str(e)}

        kpi_views = project.get('kpi_views', 1000)
        project_name = project['name']

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è fetch –¥–∞–Ω–Ω—ã—Ö (–¢–û–õ–¨–ö–û API –∑–∞–ø—Ä–æ—Å, –ë–ï–ó –∑–∞–ø–∏—Å–∏ –≤ –ë–î/Sheets)
        def fetch_account_stats(account):
            """
            Fetch —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–∫–∫–∞—É–Ω—Ç–∞ –∏–∑ API (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö)

            –í–ê–ñ–ù–û: –ù–ï –¥–µ–ª–∞–µ—Ç –∑–∞–ø–∏—Å—å –≤ –ë–î/Sheets, —Ç–æ–ª—å–∫–æ fetch!
            –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç SQLite lock'–∏ –∏ race conditions.
            """
            platform = account.get('platform', 'tiktok').lower()
            profile_link = account.get('profile_link', '')
            username = account.get('username', '')

            try:
                api_client = get_api_client(platform)
                if not api_client:
                    return {
                        'success': False,
                        'account': account,
                        'username': username,
                        'error': f'{platform} API not available'
                    }

                # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–¢–û–õ–¨–ö–û fetch)
                stats = None
                if platform == 'tiktok':
                    stats = api_client.get_tiktok_data(profile_link, kpi_views=kpi_views,
                                                       date_from=date_from, date_to=date_to)
                elif platform == 'instagram':
                    stats = api_client.get_instagram_data(profile_link, kpi_views=kpi_views,
                                                          date_from=date_from, date_to=date_to)
                elif platform == 'facebook':
                    result = api_client.get_page_reels(profile_link, kpi_views=kpi_views,
                                                       date_from=date_from, date_to=date_to)
                    if result.get('success'):
                        stats = {
                            'total_views': result.get('total_views', 0),
                            'total_likes': result.get('total_likes', 0),
                            'videos': result.get('total_videos', 0),
                            'total_videos_fetched': result.get('total_videos', 0),
                            'followers': 0,
                            'likes': result.get('total_likes', 0)
                        }

                if not stats:
                    return {
                        'success': False,
                        'account': account,
                        'username': username,
                        'error': 'No stats returned'
                    }

                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ (–ë–ï–ó –∑–∞–ø–∏—Å–∏!)
                return {
                    'success': True,
                    'account': account,
                    'username': username,
                    'stats': stats,
                    'profile_link': profile_link
                }

            except Exception as e:
                logger.error(f"‚ùå [Celery] Error fetching {username}: {e}")
                return {
                    'success': False,
                    'account': account,
                    'username': username,
                    'error': str(e)
                }

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –±–∞—Ç—á–∞–º–∏ —Å –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–æ–º
        processed = 0
        updated = 0
        failed = 0
        results = []

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
        platform_stats = {}
        for account in filtered_accounts:
            platform = account.get('platform', 'tiktok').lower()
            if platform not in platform_stats:
                platform_stats[platform] = {
                    'total': 0,
                    'processed': 0,
                    'updated': 0,
                    'failed': 0
                }
            platform_stats[platform]['total'] += 1

        for batch_start in range(0, total_to_process, BATCH_SIZE):
            batch_end = min(batch_start + BATCH_SIZE, total_to_process)
            batch = filtered_accounts[batch_start:batch_end]
            batch_num = batch_start // BATCH_SIZE + 1

            logger.info(f"üîÑ [Celery] Batch {batch_num}: Fetching stats for accounts {batch_start+1}-{batch_end}")

            # –®–ê–ì 1: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π FETCH (–≤ –ø–æ—Ç–æ–∫–∞—Ö) —Å –†–ï–ê–õ-–¢–ê–ô–ú –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            fetch_results = []
            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                futures = [executor.submit(fetch_account_stats, acc) for acc in batch]

                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ –º–µ—Ä–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ fetch
                for future in as_completed(futures):
                    fetch_result = future.result()
                    fetch_results.append(fetch_result)

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á—ë—Ç—á–∏–∫ –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –°–†–ê–ó–£
                    account = fetch_result['account']
                    platform = account.get('platform', 'tiktok').lower()
                    if platform in platform_stats:
                        platform_stats[platform]['processed'] += 1

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –ö–ê–ñ–î–û–ì–û fetch –¥–ª—è —Ä–µ–∞–ª-—Ç–∞–π–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                    current_processed = processed + len(fetch_results)
                    progress_percent = int(current_processed / total_to_process * 100)
                    logger.info(f"üîÑ [Celery] Updated progress: {platform} {platform_stats[platform]['processed']}/{platform_stats[platform]['total']}")
                    db.update_job(
                        job_id,
                        progress=progress_percent,
                        processed=current_processed,
                        meta=platform_stats
                    )

            logger.info(f"‚úÖ [Celery] Batch {batch_num}: Fetched {len(fetch_results)} accounts")
            logger.info(f"üîç [Celery] Final progress after batch fetch: {platform_stats}")

            # –®–ê–ì 3: –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ó–ê–ü–ò–°–¨ (–≤ –≥–ª–∞–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ, –ë–ï–ó –ø–æ—Ç–æ–∫–æ–≤!)
            logger.info(f"üíæ [Celery] Batch {batch_num}: Writing to DB/Sheets...")

            for fetch_result in fetch_results:
                processed += 1
                account = fetch_result['account']
                platform = account.get('platform', 'tiktok').lower()

                if fetch_result['success']:
                    try:
                        stats = fetch_result['stats']
                        username = fetch_result['username']
                        profile_link = fetch_result['profile_link']

                        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ Google Sheets
                        stats_dict = {
                            'followers': stats.get('followers', 0),
                            'likes': stats.get('likes', stats.get('total_likes', 0)),
                            'videos': stats.get('videos', stats.get('reels', 0)),
                            'views': stats.get('total_views', 0),
                            'comments': 0
                        }
                        sheets_manager.update_account_stats(
                            project_name=project_name,
                            username=username,
                            stats=stats_dict,
                            profile_link=profile_link
                        )

                        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º snapshot –≤ SQLite
                        project_manager.add_account_snapshot(
                            account_id=account['id'],
                            followers=stats.get('followers', 0),
                            likes=stats.get('likes', stats.get('total_likes', 0)),
                            comments=0,
                            videos=stats.get('videos', stats.get('reels', 0)),
                            views=stats.get('total_views', 0),
                            total_videos_fetched=stats.get('total_videos_fetched',
                                                           stats.get('total_reels_fetched', 0))
                        )

                        updated += 1
                        if platform in platform_stats:
                            platform_stats[platform]['updated'] += 1

                        results.append({
                            'success': True,
                            'username': username,
                            'views': stats.get('total_views', 0)
                        })

                        logger.info(f"‚úÖ [Celery] Wrote {username}: {stats.get('total_views', 0)} views")

                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ write –¥–ª—è —Ä–µ–∞–ª-—Ç–∞–π–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                        progress_percent = int((processed / total_to_process) * 100)
                        db.update_job(
                            job_id,
                            progress=progress_percent,
                            processed=processed,
                            meta=platform_stats
                        )

                    except Exception as e:
                        logger.error(f"‚ùå [Celery] Error writing {fetch_result['username']}: {e}")
                        failed += 1
                        if platform in platform_stats:
                            platform_stats[platform]['failed'] += 1
                        results.append({
                            'success': False,
                            'username': fetch_result['username'],
                            'error': f'Write failed: {str(e)}'
                        })

                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ failed write
                        progress_percent = int((processed / total_to_process) * 100)
                        db.update_job(
                            job_id,
                            progress=progress_percent,
                            processed=processed,
                            meta=platform_stats
                        )
                else:
                    # Fetch failed
                    failed += 1
                    if platform in platform_stats:
                        platform_stats[platform]['failed'] += 1
                    results.append({
                        'success': False,
                        'username': fetch_result['username'],
                        'error': fetch_result.get('error', 'Unknown error')
                    })

                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ failed fetch
                    progress_percent = int((processed / total_to_process) * 100)
                    db.update_job(
                        job_id,
                        progress=progress_percent,
                        processed=processed,
                        meta=platform_stats
                    )

            # –®–ê–ì 4: –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –∑–∞–ø–∏—Å–∏ (–æ–±–Ω–æ–≤–ª—è–µ–º updated/failed —Å—á–µ—Ç—á–∏–∫–∏)
            progress_percent = int((processed / total_to_process) * 100)
            logger.info(f"üîç [Celery] Updating job after write with platform_stats: {platform_stats}")
            db.update_job(
                job_id,
                progress=progress_percent,
                processed=processed,
                meta=platform_stats
            )

            logger.info(f"üìä [Celery] Batch {batch_num} complete: {processed}/{total_to_process} ({progress_percent}%) | ‚úÖ {updated} | ‚ùå {failed}")

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ (–∏–∑–±–µ–≥–∞–µ–º rate limits)
            if batch_end < total_to_process:
                logger.info(f"‚è∏Ô∏è [Celery] Waiting {BATCH_DELAY}s before next batch...")
                time.sleep(BATCH_DELAY)

        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ job
        final_result = {
            'total': total_to_process,
            'updated': updated,
            'failed': failed,
            'results': results[:10]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞
        }

        logger.info(f"üîç [Celery] Final update with platform_stats: {platform_stats}")
        db.update_job(
            job_id,
            status='completed',
            progress=100,
            processed=total_to_process,
            result=final_result,
            meta=platform_stats
        )

        logger.info(f"‚úÖ [Celery] Refresh completed: {updated} updated, {failed} failed")

        return {
            'success': True,
            'updated': updated,
            'failed': failed,
            'total': total_to_process
        }

    except Exception as e:
        logger.error(f"‚ùå [Celery] Refresh task failed: {e}")
        if db:
            db.update_job(job_id, status='failed', error=str(e))
        return {'success': False, 'error': str(e)}

    finally:
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î
        if db:
            try:
                db.conn.close()
            except:
                pass


# Periodic Tasks Schedule (Celery Beat)
if CELERY_AVAILABLE and celery_app:
    celery_app.conf.beat_schedule = {
        'smart-sync-all-projects-every-5-minutes': {
            'task': 'smart_sync_all_projects',
            'schedule': 300.0,  # 5 minutes - –±—ã—Å—Ç—Ä—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        },
    }

if __name__ == '__main__':
    logger.info("üöÄ Celery worker started")
    logger.info(f"üì° Broker: {broker_url}")
    logger.info(f"üíæ Backend: {result_backend}")
